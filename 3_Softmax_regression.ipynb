{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3. Softmax regression.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/scumabo/DeepLearningFromScratch/blob/master/3_Softmax_regression.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "h3sw8YQpwyUe",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "82e90c3e-8615-4c9a-88eb-a86ed567cee8"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "%matplotlib inline\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-fdeb83bb-b342-4ab8-9c90-277512d7d7da\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-fdeb83bb-b342-4ab8-9c90-277512d7d7da\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving MNIST_train.csv to MNIST_train.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Cw5mAwRQz3ZW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "5ab7c3db-c76d-41ef-d65d-608f6af2a94f"
      },
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"MNIST_train.csv\").values\n",
        "\n",
        "X_data = data[:, 1:]\n",
        "Y_data = data[:, [0]]\n",
        "\n",
        "# Simple normalization\n",
        "X_data = X_data / 255\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X_data, Y_data, random_state = 0)\n",
        "\n",
        "print(\"Number of training examples = \" + str(X_train.shape[0]) )\n",
        "print(\"Number of testing examples = \" + str(X_test.shape[0]) )\n",
        "print(\"Number of features = \" +  str(X_train.shape[1]) )"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training examples = 31500\n",
            "Number of testing examples = 10500\n",
            "Number of features = 784\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "lzl5z5ZVz83y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "d7f196ee-911a-4ade-b763-d0c1b50ebf93"
      },
      "cell_type": "code",
      "source": [
        "index = 10\n",
        "sampleImg = np.reshape(X_train[index, :], [28, 28])\n",
        "\n",
        "ax = plt.imshow(sampleImg)\n",
        "plt.title(\"label is \" + str(Y_train[index, :]))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5,1,'label is [5]')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPoAAAEHCAYAAACHl1tOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAEOtJREFUeJzt3X+sVPWZx/H35ZqrcsEisHj9gTGk\n7oNGopFdg0GEVlyJ1WqCpru6yKppm63XdK1K1C4KarSBWHb90TaGXWnMmgjqqrRIEVtwbULqElpF\n22eBZV24QC7+KAqUC1zYP2a4O3O558wwd87MXJ7P6x/mnO98zzxM+HC+55w559t0+PBhROT4Nqje\nBYhI9hR0kQAUdJEAFHSRABR0kQAUdJEATqh3AVI+M5sCLHT3L5d43/8Af+vu7xzDthcBG9390V7r\nHwc+cveflLmdOUA7sBb4NrAB2FTwlt8A9wKrgbOBq919Vbl1SmUUdEnl7vdX0O1pd59jZucAHe4+\nto/3jDWzVf0qTsqmoA9QZjYYeA64CGgBXnb3ewre8lUzewoYCfzU3f8x3+864FGgFdgI3OTuH6d8\nziLye3ozawfuAJqAz4Fb3f2Dqv/lpOp0jD5w/T0wFBgLXAz8nZldVtA+HviL/J/fMbMLzWwM8Dzw\nN+4+BvgVUO6QfCjwCHBJfg89H/haGV1PMbNXzewPZrbczM4r8+8nVaSgD1Du/gRwnbsfdvfPgA+A\nMQVv+Td373b3TnLHw5cC04BV7r4+/56fAF83s+YyPnIfcBi43cxOc/cl7j6vRJ8vgBeAfwDOB94E\nXjMzjSRrTF/4AGVm5wI/NLOxQDcwmtxQ/oidBa93AaeSG3JfbmZ/6NU2otTnufsBM7sCeACYa2bv\nAd9x9/dT+nxC7sTckZp/CDwI/DnwYanPlOpR0AeuZ8id2b7e3bvN7Ne92ocXvD4V+BToAla6+w29\nN2ZmJT/Q3dcBN5pZCzCL3IhgYtL7zexUYJi7by5Y3QwcKPlhUlUaug9co4B1+ZBfCZwLDClo/2sz\nG2Rmo4BJwH8AvwAm5Y/VMbNLzOyfy/kwMxtnZkvMrMXd9wP/SW4on+YvgV+a2Z/ll78J/C/w32X+\nHaVKtEcfuB4FFpjZg8CrwFzgYTNbl29/l9w161HAAnf/EMDMvgn8e36v/AW54+dyrAc2Ax+Y2f58\n3zvSOrj7CjP7EfBrMzsEdADT3b37GP6eUgVNuh9dqin/gxncfU4Z710FzNEPZrKnobtIAAq6ZKHd\nzH6R1Ghmp+XP/F9Sw5pC09BdJADt0UUCqNVZdw0bRLLXlNRQcdDNbAEwgVyIv+vu71a6LRHJVkVD\ndzObDJzr7pcCtwNPVrUqEamqSo/RryD3Iw3c/ffAqWZ2StWqEpGqqjTobRTfNLEzv05EGlC1zron\nngQQkfqrNOjbKN6DnwFs7385IpKFSoO+ArgBwMwuBra5+xdVq0pEqqriX8aZ2Q+Ay4FDwB3u/ruU\nt+s6ukj2Eg+ha/UTWAVdJHuJQddPYEUCUNBFAlDQRQJQ0EUCUNBFAlDQRQJQ0EUCUNBFAlDQRQJQ\n0EUCUNBFAlDQRQJQ0EUCUNBFAlDQRQJQ0EUCUNBFAlDQRQJQ0EUCUNBFAlDQRQJQ0EUCUNBFAlDQ\nRQJQ0EUCUNBFAlDQRQJQ0EUCUNBFAjih3gXI8Wnfvn2JbTt27Ejtu2TJkn59du8ZgmfNmsW8efMA\n6OzsTO27d+/e1PYj20kyZMiQMiqsvYqCbmZTgCXAB/lV77v7ndUqSkSqqz979NXufkPVKhGRzOgY\nXSSApt7HM+XID91/BGwEhgNz3f3NlC7H/iEicqyaEhsqDPqZwGXAYmAM8Cvgy+6+P6GLgh6MTsbV\nRWLQKzpGd/cO4MX84iYz2wGcCWyuZHsikq2KjtHN7GYzuyf/ug04DeioZmEiUj2VDt2HAi8Aw4AW\ncsfoy1K6aOheY5999llq+/r161PbSw1x33nnnaLlBQsWcNddd/Usr1ixIrGvu6duu7+am5uLlru6\nujjxxBMBGDZsWGrfAwcOpLZv2LAhtX3EiBFlVJiZqg/dvwCurbgcEakpXV4TCUBBFwlAQRcJQEEX\nCUBBFwmgostrFdDltRq76aabUtsXL17cr+33/nfT3d1ddFmrqSnxSk/mWlpaipb37t3L4MGDARg1\nalRq3xkzZqS2P/LII/0rLluJX7r26CIBKOgiASjoIgEo6CIBKOgiASjoIgEo6CIB6HHPGVq3bl1q\n+513pj8496WXXipabmtrK3o6S1tbW2LfcePGpW67v9fRs3Teeeelts+dOze1fcKECUet27hxI1D6\n+v7w4cNLVDcwaY8uEoCCLhKAgi4SgIIuEoCCLhKAgi4SgIIuEoDuR8/Qli1bUttLXevuPevH1q1b\nOeuss3qW165dm9h3586dqdu+6KKLUttLKXU/+t13353Y96GHHkrd9gknpP+848ijm+Uouh9dJDIF\nXSQABV0kAAVdJAAFXSQABV0kAAVdJABdR6+jwmvifenoKJ5y/vDhw0X3Uy9dujSx7zXXXNO/4mQg\n6t+0yWZ2AfAasMDdnzaz0cDzQDOwHZjh7l3VqFREqq/k0N3MWoGngLcKVj8MPOPuk4CNwG3ZlCci\n1VDOMXoXcDWwrWDdFOD1/OulwNTqliUi1VRy6O7uB4GDZla4urVgqN4JnJ5Bbce9rVu3HnOfGp1T\nkeNMNR4OWb/Z9AY4nYyTWqn08tpuMzs5//pMiof1ItJgKg36SmB6/vV0YHl1yhGRLJS8jm5m44En\ngHOAA0AHcDOwCDgJ+Ai41d0PpGxGB5Z9WLNmTWr7xIkTi5Z73/M9cuTIxL6rV69O3fbYsWPLqFAG\nmMqvo7v7WnJn2Xu7sh8FiUgN6SewIgEo6CIBKOgiASjoIgEo6CIB6DbVBtbrZ8e4e9G6TZs2Jfad\nPHly6raXLVuW2q5HKg9IetyzSGQKukgACrpIAAq6SAAKukgACrpIAAq6SAC6jt7AVq5cWbQ8derU\nonXTpk2reNuPPfZYavusWbMq3rbUja6ji0SmoIsEoKCLBKCgiwSgoIsEoKCLBKCgiwSg6+gN7NCh\nQ0XLgwYNKlrX3t6e2PfZZ59N3Xap+9XfeOON1PaWlpbUdqkLXUcXiUxBFwlAQRcJQEEXCUBBFwlA\nQRcJQEEXCUDX0Qewbdu2JbaNHj26X9uePXt2avucOXP6tX3JROXTJgOY2QXAa8ACd3/azBYB44FP\n8m+Z7+4/72+VIpKNkkE3s1bgKeCtXk33u/vPMqlKRKqqnGP0LuBqIHmcKCINreQe3d0PAgd7zwMG\ntJvZ94BOoN3dP86gPklxxhlnJLZ1d3fXsBJpdGUdo/fheeATd/+tmd0HzAGS77CQTOhknJSroqC7\ne+Hx+uvAj6tTjohkoaLr6Gb2spmNyS9OAdZXrSIRqbqS19HNbDzwBHAOcADoIHcW/j5gL7AbuNXd\nO1M2o+voGdi3b19i2y233JLa95VXXunXZ+/atatoubW1lT179hQtS81Vfh3d3deS22v39nI/ChKR\nGtJPYEUCUNBFAlDQRQJQ0EUCUNBFAtBtqsepLVu2pLZfeOGFqe2ff/55avvUqVOLlpcvX140jfPy\n5ctLVCgZ0OOeRSJT0EUCUNBFAlDQRQJQ0EUCUNBFAlDQRQKo9Akz0uBKPWHm/PPPT21fs2ZNavuH\nH35Y1jppDNqjiwSgoIsEoKCLBKCgiwSgoIsEoKCLBKCgiwSg6+hBXXbZZantpa6jb9++PXVdWv8J\nEyaUqE6qTXt0kQAUdJEAFHSRABR0kQAUdJEAFHSRABR0kQDKuo5uZvOASfn3Pw68CzwPNAPbgRnu\n3pVVkY1q//79qe0tLS01quTYTZw4MbV9/vz5qe3d3d1HrTt48GDP666ucP8cGlrJPbqZfQW4wN0v\nBaYB/wQ8DDzj7pOAjcBtmVYpIv1SztD9beDG/Os/Aq3k5kt/Pb9uKTD16G4i0ihKDt3dvRvYk1+8\nHVgGXFUwVO8ETs+mPBGphrJ/625m15EL+l8BGwqaEud7Ot418jF4Kddee21qe1/H4KXUaB4/qUC5\nJ+OuAr4PTHP3XWa228xOdvc/AWcC27IsslEN5JNxS5cuTW2//vrrU9sPHTpUtHz48GGamv7///xV\nq1Yl9p08eXLpAqWqyjkZ9yVgPnCNu3+aX70SmJ5/PR3Q1JkiDaycPfo3gJHAYjM7sm4msNDMvg18\nBPw0m/Lqb8+ePYltM2fOTO179tlnp7a3t7entg8ePLhoua2tjR07dvQsjxgxIrHvvn37Urf94IMP\nprYX7p37MmjQ0fuIvtZJYyjnZNyzwLN9NF1Z/XJEJAv6L1gkAAVdJAAFXSQABV0kAAVdJAAFXSQA\nPe65hNbW1sS2e++9N7Xvk08+mdo+bty41PbePyndu3cvY8aM6VmeMmVKYt/NmzenbnvDhg2p7XJ8\n0R5dJAAFXSQABV0kAAVdJAAFXSQABV0kAAVdJICmGj3+R88Y6kOp+9U7OjqKlru7u2lubu5ZLnXP\neJZOOumkouXdu3czZMiQnuX33nsvsW/hbwGkqhL/QWiPLhKAgi4SgIIuEoCCLhKAgi4SgIIuEoCC\nLhKA7kevowceeCC1vfAZ7kfMnj275/XChQsT+w4dOjR126XuRy/8nL70dS9+Z2dnz+vez6SX+tIe\nXSQABV0kAAVdJAAFXSQABV0kAAVdJAAFXSSAsu5HN7N5wCRy190fB74OjAc+yb9lvrv/PGUTuh9d\nJHuJ96OX/MGMmX0FuMDdLzWzEcA64JfA/e7+s+rVKCJZKeeXcW8Dv8m//iPQCjQnv11EGs0xPUrK\nzL5FbgjfDbQBLUAn0O7uH6d01dBdJHv9f5SUmV0H3A60A88D97n7V4HfAnP6WaCIZKism1rM7Crg\n+8A0d98FvFXQ/Drw4wxqE5EqKblHN7MvAfOBa9z90/y6l83syKM8pwDrM6tQRPqtnD36N4CRwGIz\nO7LuOeBFM9sL7AZuzaY8EakGPddd5Pih57qLRKagiwSgoIsEoKCLBKCgiwSgoIsEoKCLBKCgiwSg\noIsEoKCLBKCgiwSgoIsEoKCLBKCgiwRQq2mTE2+fE5HsaY8uEoCCLhKAgi4SgIIuEoCCLhKAgi4S\ngIIuEkCtrqP3MLMFwARyj4D+rru/W+sa+mJmU4AlwAf5Ve+7+531qwjM7ALgNWCBuz9tZqPJTYfV\nDGwHZrh7V4PUtohjm0o7y9p6T/P9Lg3wvVVh+vGK1TToZjYZODc/BfN5wL8Cl9ayhhJWu/sN9S4C\nwMxagaconv7qYeAZd19iZo8Bt1GH6bASaoMGmEo7YZrvt6jz91bv6cdrPXS/AngVwN1/D5xqZqfU\nuIaBogu4GthWsG4KubnuAJYCU2tc0xF91dYo3gZuzL8+Ms33FOr/vfVVV82mH6/10L0NWFuwvDO/\n7vMa15HkfDN7HRgOzHX3N+tViLsfBA4WTIMF0Fow5OwETq95YSTWBtBuZt+jvKm0s6qtG9iTX7wd\nWAZcVe/vLaGubmr0ndX7ZFwj/QZ+AzAXuA6YCfyLmbXUt6RUjfTdQYNNpd1rmu9Cdf3e6jX9eK33\n6NvI7cGPOIPcyZG6c/cO4MX84iYz2wGcCWyuX1VH2W1mJ7v7n8jV1jBDZ3dvmKm0e0/zbWYN8b3V\nc/rxWu/RVwA3AJjZxcA2d/+ixjX0ycxuNrN78q/bgNOAjvpWdZSVwPT86+nA8jrWUqRRptLua5pv\nGuB7q/f047WaTbWHmf0AuBw4BNzh7r+raQEJzGwo8AIwDGghd4y+rI71jAeeAM4BDpD7T+dmYBFw\nEvARcKu7H2iQ2p4C7gN6ptJ298461PYtckPg/ypYPRNYSB2/t4S6niM3hM/8O6t50EWk9up9Mk5E\nakBBFwlAQRcJQEEXCUBBFwlAQRcJQEEXCeD/AAzy56N5Fl43AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f15ad646fd0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "mPgrfU0I1J_Y",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Convert labels to its one-hot encoding for defining the loss function of softmax classification"
      ]
    },
    {
      "metadata": {
        "id": "6ohVzSiH0_6q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def one_hot_matrix(Y, num_class):\n",
        "    \"\"\"\n",
        "    Convert an array of Y to its one_hot_matrix\n",
        "    \n",
        "    Arguments:\n",
        "    Y -- array (number of examples, 1)\n",
        "    num_class -- num of classes\n",
        "    \n",
        "    Return:\n",
        "    Y_one_hot -- (number of examples, num_class)\n",
        "    \"\"\"\n",
        "    Y_one_hot = np.zeros((Y.shape[0], num_class))\n",
        "    Y_one_hot[np.arange(Y.shape[0]), Y.T] = 1\n",
        "    \n",
        "    return Y_one_hot"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "x8GS9x8-1PUU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "684d68e6-3f1e-4ac3-e97f-58e3b97a1b1c"
      },
      "cell_type": "code",
      "source": [
        "Y_train_one_hot = one_hot_matrix(Y_train, 10)\n",
        "Y_test_one_hot = one_hot_matrix(Y_test, 10)\n",
        "\n",
        "index = 2\n",
        "print(\"Letter \" + str(Y_train[index, 0]) + \" converted to \" + str(Y_train_one_hot[index, :]))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Letter 9 converted to [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "owis259q1Zem",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Math for one training example\n",
        "\n",
        "###  1. Forward propagation\n",
        "\n",
        "We treate the softmax classification problem as a 1-layer neural network with 10 nerons (add image). Each neural is just a linear combination of all input features, and the softmax activation function takes effect for all neurons.\n",
        "\n",
        "For one example $\\{x_1, ..., x_{n} \\}$ (use column vectors in the following for legibility):\n",
        "\n",
        "#### Linear forward\n",
        "\n",
        "$$\n",
        "Z\n",
        "=\n",
        "\\begin{bmatrix} \n",
        "z_1 \\\\\n",
        "\\vdots \\\\\n",
        "z_j \\\\\n",
        "\\vdots \\\\\n",
        "z_{10} \\\\\n",
        "\\end{bmatrix}\n",
        "=\n",
        "\\begin{bmatrix} \n",
        "\\sum\\limits_{i=1}^{n} w_{i, 1} x_{i} \\\\\n",
        "\\vdots \\\\\n",
        "\\sum\\limits_{i=1}^{n} w_{i, j} x_{i} \\\\\n",
        "\\vdots \\\\\n",
        "\\sum\\limits_{i=1}^{n} w_{i, 10} x_{i} \\\\\n",
        "\\end{bmatrix}\n",
        "+\n",
        "\\begin{bmatrix} \n",
        "b_1 \\\\\n",
        "\\vdots \\\\\n",
        "b_j \\\\\n",
        "\\vdots \\\\\n",
        "b_{10} \\\\\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "\n",
        "#### Softmax\n",
        "\n",
        "$$\n",
        "\\begin{bmatrix} \n",
        "z_1 \\\\\n",
        "\\vdots \\\\\n",
        "z_{10} \\\\\n",
        "\\end{bmatrix}\n",
        "\\Rightarrow \n",
        "\\begin{bmatrix} \n",
        "\\frac{e^{z_1} }{\\sum\\limits_{k = 1}^{10} e^{z_k} } \\\\\n",
        "\\vdots \\\\\n",
        "\\frac{e^{z_10} }{\\sum\\limits_{k = 1}^{10} e^{z_k} } \\\\\n",
        "\\end{bmatrix}=\n",
        "\\begin{bmatrix} \n",
        "a_1 \\\\\n",
        "\\vdots \\\\\n",
        "a_{10} \\\\\n",
        "\\end{bmatrix}=\n",
        "a\n",
        "$$\n",
        "\n",
        "\n",
        "### 2. Cross entropy loss\n",
        "\n",
        "$$ \\mathcal{L}(a, y) = -\\sum\\limits_{j = 1} ^{10} y_{j} \\log a_{j} $$\n",
        "\n",
        "### 3. Backward propagation\n",
        "\n",
        "#### 1. Derivative of linear function\n",
        "\n",
        "$$ \\frac{\\partial z_j }{\\partial w_{i, j}} =  x_i $$\n",
        "\n",
        "$$ \\frac{\\partial z_j }{\\partial b_{j}} =  1 $$\n",
        "\n",
        "\n",
        "#### 2. Derivative of the softmax function\n",
        "\n",
        "Let $\\Omega =  \\sum\\limits_{k = 1}^{10} e^{z_k}$, let compute the partial derivatives for the Jacobian matrix (10 x 10) $\\frac{\\partial a_p}{\\partial z_q}$:\n",
        "\n",
        "$$\n",
        "\\begin{split}\n",
        "\\text{if} \\; p = q :& \\frac{\\partial a_p}{\\partial z_p} = \\frac{\\partial \\frac{e^{z_p}}{\\Omega}}{\\partial z_p} = \\frac{e^{z_p}\\Omega - e^{z_p}e^{z_p}}{\\Omega^2} = \\frac{e^{z_p}}{\\Omega}\\frac{\\Omega - e^{z_p}}{\\Omega} = \\frac{e^{z_p}}{\\Omega}(1-\\frac{e^{z_p}}{\\Omega}) =  y_p (1 - y_p)\\\\\n",
        "\\text{if} \\; p \\neq q :& \\frac{\\partial y_p}{\\partial z_q} = \\frac{\\partial \\frac{e^{z_p}}{\\Omega}}{\\partial z_q} = \\frac{0 - e^{z_p}e^{z_q}}{\\Omega^2} = -\\frac{e^{z_p}}{\\Omega} \\frac{e^{z_1}}{\\Omega} = -y_p y_q\n",
        "\\end{split}\n",
        "$$\n",
        "\n",
        "#### 3. Derivative of the cross entropy loss for the softmax function\n",
        "$$\\begin{split}\n",
        "\\frac{\\partial \\mathcal{L}}{\\partial z_i} & = - \\sum_{j=1}^{10} \\frac{\\partial y_j log(a_j)}{\\partial z_i}{} =\n",
        "- \\sum_{j=1}^{10} y_j \\frac{\\partial log(a_j)}{\\partial z_i} = - \\sum_{j=1}^{10} y_j \\frac{1}{a_j} \\frac{\\partial a_j}{\\partial z_i} \\\\\n",
        "& = - \\frac{y_i}{a_i} \\frac{\\partial a_i}{\\partial z_i} - \\sum_{j \\neq i}^{10} \\frac{y_j}{a_j} \\frac{\\partial a_j}{\\partial z_i}\n",
        "= - \\frac{y_i}{a_i} a_i (1-a_i) - \\sum_{j \\neq i}^{10} \\frac{y_j}{a_j} (-a_j a_i) \\\\\n",
        "& = - y_i + y_i a_i + \\sum_{j \\neq i}^{10} y_j a_i = - y_i + \\sum_{j = 1}^{10} y_j a_i\n",
        "= -y_i + a_i \\sum_{j = 1}^{10} y_j \\\\\n",
        "& = a_i - y_i\n",
        "\\end{split}$$\n",
        "\n",
        "#### 3. Derivative of the cross entropy loss for $w$ and $b$\n",
        "\n",
        "$$\\frac{\\partial \\mathcal{L} }{\\partial w_{i, j}} = \\frac{\\partial \\mathcal{L}}{\\partial z_j} \\frac{\\partial z_j }{\\partial w_{i, j}} = (a_j - y_j) x_i $$\n",
        "\n",
        "$$\\frac{\\partial \\mathcal{L} }{\\partial b_{j}} = \\frac{\\partial \\mathcal{L}}{\\partial z_j} \\frac{\\partial z_j }{\\partial b_{j}} = a_j - y_j $$"
      ]
    },
    {
      "metadata": {
        "id": "D7unQjyK1ecT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Vectorization for m training examples \n",
        "\n",
        "\n",
        "### 1. Forward propagation\n",
        "\n",
        "let's use the convention that the data matrix $X$ with shape $m \\times n$ has $m$ training examples and $n$ features for each example:\n",
        "\n",
        "$$\n",
        "X_{(m, n)}=\n",
        "\\begin{bmatrix} \n",
        "\\dots x^{(1)} \\dots \\\\\n",
        "\\vdots \\\\\n",
        "\\dots x^{(m)} \\dots \\\\\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "\n",
        "$$W_{(n, 10)}=\n",
        "\\begin{bmatrix} \n",
        "\\vdots \\dots \\vdots \\\\w^{(1)} \\dots w^{(10)} \\\\ \\vdots \\dots \\vdots \\\\\n",
        "\\end{bmatrix}$$\n",
        "\n",
        "$$Z_{(m, 10)} = X W$$\n",
        "\n",
        "$$A_{(m, 10)} = \\text{softmax}(Z_{(m, 10)})$$\n",
        "\n",
        "Also, we have $Y_{(m, 10)}$, then the cross entropy loss is:\n",
        "$$J = - \\frac{1}{m} || Y * \\log A ||_{F} = - \\frac{1}{m} \\sum\\limits_{i=1}^m \\sum\\limits_{j=1}^{10} Y_{i,j} \\log A_{i,j}$$\n",
        "\n",
        "### 2. Backward propagation\n",
        "$$dZ = Y - A$$\n",
        "$$dW = \\frac{1}{m} X^T (Y - A)$$\n",
        "$$db = \\frac{1}{m} (Y - A).sum(axis = 0)$$"
      ]
    },
    {
      "metadata": {
        "id": "Tqa-SioG1fDS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def linear_forward(X, W, b):\n",
        "    \"\"\"\n",
        "    Arguments:\n",
        "    X -- data matrix (m, n)\n",
        "    W -- weight matrix (n, num of class)\n",
        "    b -- bias vector (1, num of class)\n",
        "    \n",
        "    Return: \n",
        "    Z -- input of activation function (m, 10)\n",
        "    \"\"\"\n",
        "    \n",
        "    Z = np.dot(X, W) + b\n",
        "    \n",
        "    \n",
        "    \n",
        "    assert(Z.shape == (X.shape[0], W.shape[1]) )\n",
        "    \n",
        "    return Z"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "G0v0-T1N1p-6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def soft_max(Z):\n",
        "    \"\"\"\n",
        "    Arguments:\n",
        "    Z -- (m, num of class)\n",
        "    \n",
        "    Return:\n",
        "    A -- softmax matrix (m, num of class) \n",
        "    \"\"\"\n",
        "    exp_Z = np.exp(Z)\n",
        "    A = exp_Z / exp_Z.sum(axis = 1, keepdims = True) # sum along columns\n",
        "    \n",
        "    assert(A.shape == Z.shape )\n",
        "    \n",
        "    return A"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rxqG6Kfs1scc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def initialize_parameters(n, num_class):\n",
        "    \"\"\"\n",
        "    Return:\n",
        "    W -- (n, num of class)\n",
        "    b -- (1, num of class)\n",
        "    \"\"\"\n",
        "    np.random.seed(1)\n",
        "    W = np.random.randn(n, num_class) * 0.01\n",
        "    b = np.zeros((1, num_class))\n",
        "    \n",
        "    return W, b"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oEk5PLnE1vQb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 2. Compute the cost function\n",
        "The cross entropy loss function for one example is $\\mathcal{L}(a, y) = -\\sum\\limits_{j = 1}^{10} a_{j} \\log y_{j}$. The overall loss is just the average of $\\mathcal{L}$ over all training examples: $$ J = \\frac{1}{m} \\sum\\limits_{i = 1}^{m} \\mathcal{L}(a^{(i)}, y^{(i)}) $$"
      ]
    },
    {
      "metadata": {
        "id": "icTMKOLp1t4y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "937f4a60-332a-4b41-9b6d-60195bacf306"
      },
      "cell_type": "code",
      "source": [
        "x = np.linspace(0.001, 1)\n",
        "y = - np.log(x)\n",
        "plt.plot(x, y)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f15ad28b208>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWkAAAD4CAYAAAAuNhccAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f15ad337358>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "sXQmzmaw1yax",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "If $a_j = 1$, the cost function want $y_j$ to be large while it heavily penalizes small $y_j$. "
      ]
    },
    {
      "metadata": {
        "id": "I2e40Qnp12NO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def compute_cross_entropy_loss(A, Y):\n",
        "    \"\"\"\n",
        "    Arguments:\n",
        "    A -- prediction matrix of shape   (num of examples, num of class)\n",
        "    Y -- one-hot matrix of true class (num of examples, num of class)\n",
        "    Return:\n",
        "    lost (scalar)\n",
        "    \"\"\"\n",
        "    m = A.shape[0]\n",
        "    return -(Y * np.log(A)).sum() / m"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hkU11hwr14VR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def backward_propagation(X, A, Y):\n",
        "    \"\"\"\n",
        "    Arguments:\n",
        "    X -- data matrix shape:  (m, n)\n",
        "    A -- output of softmax:  (m, 10)\n",
        "    Y -- one-hot true labels:(m, 10)\n",
        "    \"\"\"\n",
        "    m = X.shape[0]\n",
        "    \n",
        "    dZ = A - Y\n",
        "    dW = 1/m * np.dot(X.T, dZ)\n",
        "    db = 1/m * np.sum(dZ, axis = 0, keepdims = True)\n",
        "    \n",
        "    return dW, db"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KRHEF3iY16oB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now Let's verify the correctness of our backward propagation using gradient checking. The idea is to compare the analytical derivatives to the numerical derivatives using central difference. Let's just do this for weight matrix $W$"
      ]
    },
    {
      "metadata": {
        "id": "yHD2TT0K148D",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def gradient_check(W, dW, X, Y, epsilon = 1e-7):\n",
        "    \"\"\"\n",
        "    Arguments:\n",
        "    W --  current weight matrix (num of feature, 10)\n",
        "    dW -- analytical derivative matrix (num of feature, 10)\n",
        "    X --  data matrix (num of examples, num of feature)\n",
        "    Y --  one-hot label (num of examples, 10)\n",
        "    \n",
        "    Return:\n",
        "    difference\n",
        "    \"\"\"\n",
        "    gradApprox = np.zeros((dW.shape[0], dW.shape[1]))\n",
        "    for i in range(0, W.shape[0]):\n",
        "        for j in range(0, W.shape[1]):\n",
        "            W_plus = np.copy(W)\n",
        "            W_minus = np.copy(W)\n",
        "            \n",
        "            W_plus[i, j] = W_plus[i, j] + epsilon\n",
        "            W_minus[i, j] = W_minus[i, j] - epsilon\n",
        "            \n",
        "            Z_plus = linear_forward(X, W_plus, b)\n",
        "            A_plus = soft_max(Z_plus)\n",
        "            J_plus = compute_cross_entropy_loss(A_plus, Y)\n",
        "\n",
        "            Z_minus = linear_forward(X, W_minus, b)\n",
        "            A_minus = soft_max(Z_minus)\n",
        "            J_minus = compute_cross_entropy_loss(A_minus, Y)\n",
        "            \n",
        "            gradApprox[i, j] = (J_plus - J_minus) / (2*epsilon)\n",
        "            \n",
        "    # Compare gradients\n",
        "    numerator = np.linalg.norm(gradApprox - dW)\n",
        "    denominator = np.linalg.norm(dW) + np.linalg.norm(gradApprox)\n",
        "    difference = numerator / denominator\n",
        "    \n",
        "    if difference > 3e-7:\n",
        "        print (\"\\033[93m\" + \"There is a mistake in the backward propagation! difference = \" + str(difference) + \"\\033[0m\")\n",
        "    else:\n",
        "        print (\"\\033[92m\" + \"Your backward propagation works perfectly fine! difference = \" + str(difference) + \"\\033[0m\")\n",
        "    \n",
        "    return difference"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cBudEfbH2AaK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "num_feature = X_train.shape[1]\n",
        "num_class = 10\n",
        "\n",
        "W, b = initialize_parameters(num_feature, num_class)\n",
        "Z = linear_forward(X_train, W, b)\n",
        "A = soft_max(Z)\n",
        "dW, db = backward_propagation(X_train, A, Y_train_one_hot)\n",
        "\n",
        "#gradient_check(W, dW, X_train, Y_train_one_hot, epsilon = 1e-7)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VjlhGdhX2C96",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def mclr_model(X, Y, num_iterations = 10000, learning_rate = 1.0, print_cost = False):\n",
        "    \"\"\"\n",
        "    Arguments:\n",
        "    X -- data matrix of shape:    (m, n)\n",
        "    Y -- one-hot labels of shape: (m, num of class)\n",
        "    \n",
        "    Return:\n",
        "    W, b -- parameters of the model\n",
        "    \"\"\"\n",
        "    \n",
        "    num_feature = X.shape[1]\n",
        "    num_class = 10\n",
        "    costs = []\n",
        "    \n",
        "    W, b = initialize_parameters(num_feature, num_class)\n",
        "    \n",
        "    \n",
        "    # loop gradient decent\n",
        "    for i in range(0, num_iterations):\n",
        "        Z = linear_forward(X, W, b)\n",
        "        A = soft_max(Z)\n",
        "        \n",
        "        cost = compute_cross_entropy_loss(A, Y)\n",
        "        \n",
        "        dW, db = backward_propagation(X, A, Y)\n",
        "        \n",
        "        W = W - learning_rate * dW\n",
        "        b = b - learning_rate * db\n",
        "    \n",
        "        if print_cost and i % 100 == 0:\n",
        "            print(\"Cost after iteration %i: %f\" % (i, cost))\n",
        "        \n",
        "        costs.append(cost)\n",
        "        \n",
        "    \n",
        "    # plot the cost\n",
        "    plt.plot(np.squeeze(costs))\n",
        "    plt.ylabel('cost')\n",
        "    plt.xlabel('iterations (per hundreds)')\n",
        "    plt.title(\"learning rate = \" + str(learning_rate))\n",
        "    plt.show()\n",
        "    \n",
        "    return W, b"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MVLS45jp2E3S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        },
        "outputId": "86640fce-5977-4fd4-9ae7-4746c222a7eb"
      },
      "cell_type": "code",
      "source": [
        "W, b = mclr_model(X_train, Y_train_one_hot, num_iterations = 1000, learning_rate = 0.9, print_cost = True)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cost after iteration 0: 2.329673\n",
            "Cost after iteration 100: 0.344579\n",
            "Cost after iteration 200: 0.309545\n",
            "Cost after iteration 300: 0.293013\n",
            "Cost after iteration 400: 0.282683\n",
            "Cost after iteration 500: 0.275327\n",
            "Cost after iteration 600: 0.269677\n",
            "Cost after iteration 700: 0.265121\n",
            "Cost after iteration 800: 0.261321\n",
            "Cost after iteration 900: 0.258072\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEVCAYAAADpbDJPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nKQBERHJKASAiklMKABGRnPr/LSfjOTdjSSUAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f15ad25c128>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "pIxcpYrw2GUy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def predict(W, b, X):\n",
        "    \"\"\"\n",
        "    Arguments:\n",
        "    W -- the learned weight matrix (num_feature, num_class)\n",
        "    b -- the learned bias   matrix (1, num_class)\n",
        "    X -- input data (m, num_feature)\n",
        "    \n",
        "    Return:\n",
        "    prediction -- softmax vector (1, num_feature)\n",
        "    \"\"\"\n",
        "    A = soft_max(linear_forward(X, W, b))\n",
        "    \n",
        "    prediction = np.argmax(A, axis = 1)\n",
        "    \n",
        "    return prediction"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fHm9Xs602ISz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8f839d69-29c4-4747-8b5c-023eb1c0810c"
      },
      "cell_type": "code",
      "source": [
        "# Training accuracy\n",
        "Y_train_hat = predict(W, b, X_train)\n",
        "\n",
        "m = X_train.shape[0]\n",
        "num_correct = m - np.count_nonzero((np.squeeze(Y_train) - Y_train_hat))\n",
        "\n",
        "print(\"Training accuracy: %f\" % float(num_correct / m * 100.0) + \"%\" )"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training accuracy: 92.758730%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ud2-Hu942Iyi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5635f841-dc5b-451c-fa60-a0fd6b8743d2"
      },
      "cell_type": "code",
      "source": [
        "# Testing accuracy\n",
        "Y_test_hat = predict(W, b, X_test)\n",
        "\n",
        "m = X_test.shape[0]\n",
        "num_correct = m - np.count_nonzero((np.squeeze(Y_test) - Y_test_hat))\n",
        "\n",
        "print(\"Testing accuracy: %f\" % float(num_correct / m * 100.0) + \"%\")"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Testing accuracy: 92.352381%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "gYEFShAnCer4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}