{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Softmax logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples = 31500\n",
      "Number of testing examples = 10500\n",
      "Number of features = 784\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"data/MNIST_train.csv\").values\n",
    "\n",
    "X_data = data[:, 1:]\n",
    "Y_data = data[:, [0]]\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_data, Y_data, random_state = 0)\n",
    "\n",
    "print(\"Number of training examples = \" + str(X_train.shape[0]) )\n",
    "print(\"Number of testing examples = \" + str(X_test.shape[0]) )\n",
    "print(\"Number of features = \" +  str(X_train.shape[1]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'label is [5]')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "index = 10\n",
    "sampleImg = np.reshape(X_train[index, :], [28, 28])\n",
    "\n",
    "ax = plt.imshow(sampleImg)\n",
    "plt.title(\"label is \" + str(Y_train[index, :]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple standardization for images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train / 255\n",
    "X_test = X_test / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert labels to its one-hot encoding for defining the loss function of softmax classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_matrix(Y, num_class):\n",
    "    \"\"\"\n",
    "    Convert an array of Y to its one_hot_matrix\n",
    "    \n",
    "    Arguments:\n",
    "    Y -- array (number of examples, 1)\n",
    "    num_class -- num of classes\n",
    "    \n",
    "    Return:\n",
    "    Y_one_hot -- (number of examples, num_class)\n",
    "    \"\"\"\n",
    "    Y_one_hot = np.zeros((Y.shape[0], num_class))\n",
    "    Y_one_hot[np.arange(Y.shape[0]), Y.T] = 1\n",
    "    \n",
    "    return Y_one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Letter 9 converted to [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "Y_train_one_hot = one_hot_matrix(Y_train, 10)\n",
    "Y_test_one_hot = one_hot_matrix(Y_test, 10)\n",
    "\n",
    "index = 2\n",
    "print(\"Letter \" + str(Y_train[index, 0]) + \" converted to \" + str(Y_train_one_hot[index, :]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Math for one training example\n",
    "\n",
    "###  1. Forward propagation\n",
    "\n",
    "We treate the softmax classification problem as a 1-layer neural network with 10 nerons (add image). Each neural is just a linear combination of all input features, and the softmax activation function takes effect for all neurons.\n",
    "\n",
    "For one example $\\{x_1, ..., x_{n} \\}$ (use column vectors in the following for legibility):\n",
    "\n",
    "#### Linear forward\n",
    "\n",
    "$$\n",
    "Z\n",
    "=\n",
    "\\begin{bmatrix} \n",
    "z_1 \\\\\n",
    "\\vdots \\\\\n",
    "z_j \\\\\n",
    "\\vdots \\\\\n",
    "z_{10} \\\\\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix} \n",
    "\\sum\\limits_{i=1}^{n} w_{i, 1} x_{i} \\\\\n",
    "\\vdots \\\\\n",
    "\\sum\\limits_{i=1}^{n} w_{i, j} x_{i} \\\\\n",
    "\\vdots \\\\\n",
    "\\sum\\limits_{i=1}^{n} w_{i, 10} x_{i} \\\\\n",
    "\\end{bmatrix}\n",
    "+\n",
    "\\begin{bmatrix} \n",
    "b_1 \\\\\n",
    "\\vdots \\\\\n",
    "b_j \\\\\n",
    "\\vdots \\\\\n",
    "b_{10} \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "#### Softmax\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix} \n",
    "z_1 \\\\\n",
    "\\vdots \\\\\n",
    "z_{10} \\\\\n",
    "\\end{bmatrix}\n",
    "\\Rightarrow \n",
    "\\begin{bmatrix} \n",
    "\\frac{e^{z_1} }{\\sum\\limits_{k = 1}^{10} e^{z_k} } \\\\\n",
    "\\vdots \\\\\n",
    "\\frac{e^{z_10} }{\\sum\\limits_{k = 1}^{10} e^{z_k} } \\\\\n",
    "\\end{bmatrix}=\n",
    "\\begin{bmatrix} \n",
    "a_1 \\\\\n",
    "\\vdots \\\\\n",
    "a_{10} \\\\\n",
    "\\end{bmatrix}=\n",
    "a\n",
    "$$\n",
    "\n",
    "\n",
    "### 2. Cross entropy loss\n",
    "\n",
    "$$ \\mathcal{L}(a, y) = -\\sum\\limits_{j = 1} ^{10} y_{j} \\log a_{j} $$\n",
    "\n",
    "### 3. Backward propagation\n",
    "\n",
    "#### 1. Derivative of linear function\n",
    "\n",
    "$$ \\frac{\\partial z_j }{\\partial w_{i, j}} =  x_i $$\n",
    "\n",
    "$$ \\frac{\\partial z_j }{\\partial b_{j}} =  1 $$\n",
    "\n",
    "\n",
    "#### 2. Derivative of the softmax function\n",
    "\n",
    "Let $\\Omega =  \\sum\\limits_{k = 1}^{10} e^{z_k}$, let compute the partial derivatives for the Jacobian matrix (10 x 10) $\\frac{\\partial a_p}{\\partial z_q}$:\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "\\text{if} \\; p = q :& \\frac{\\partial a_p}{\\partial z_p} = \\frac{\\partial \\frac{e^{z_p}}{\\Omega}}{\\partial z_p} = \\frac{e^{z_p}\\Omega - e^{z_p}e^{z_p}}{\\Omega^2} = \\frac{e^{z_p}}{\\Omega}\\frac{\\Omega - e^{z_p}}{\\Omega} = \\frac{e^{z_p}}{\\Omega}(1-\\frac{e^{z_p}}{\\Omega}) =  y_p (1 - y_p)\\\\\n",
    "\\text{if} \\; p \\neq q :& \\frac{\\partial y_p}{\\partial z_q} = \\frac{\\partial \\frac{e^{z_p}}{\\Omega}}{\\partial z_q} = \\frac{0 - e^{z_p}e^{z_q}}{\\Omega^2} = -\\frac{e^{z_p}}{\\Omega} \\frac{e^{z_1}}{\\Omega} = -y_p y_q\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "#### 3. Derivative of the cross entropy loss for the softmax function\n",
    "$$\\begin{split}\n",
    "\\frac{\\partial \\mathcal{L}}{\\partial z_i} & = - \\sum_{j=1}^{10} \\frac{\\partial y_j log(a_j)}{\\partial z_i}{} =\n",
    "- \\sum_{j=1}^{10} y_j \\frac{\\partial log(a_j)}{\\partial z_i} = - \\sum_{j=1}^{10} y_j \\frac{1}{a_j} \\frac{\\partial a_j}{\\partial z_i} \\\\\n",
    "& = - \\frac{y_i}{a_i} \\frac{\\partial a_i}{\\partial z_i} - \\sum_{j \\neq i}^{10} \\frac{y_j}{a_j} \\frac{\\partial a_j}{\\partial z_i}\n",
    "= - \\frac{y_i}{a_i} a_i (1-a_i) - \\sum_{j \\neq i}^{10} \\frac{y_j}{a_j} (-a_j a_i) \\\\\n",
    "& = - y_i + y_i a_i + \\sum_{j \\neq i}^{10} y_j a_i = - y_i + \\sum_{j = 1}^{10} y_j a_i\n",
    "= -y_i + a_i \\sum_{j = 1}^{10} y_j \\\\\n",
    "& = a_i - y_i\n",
    "\\end{split}$$\n",
    "\n",
    "#### 3. Derivative of the cross entropy loss for $w$ and $b$\n",
    "\n",
    "$$\\frac{\\partial \\mathcal{L} }{\\partial w_{i, j}} = \\frac{\\partial \\mathcal{L}}{\\partial z_j} \\frac{\\partial z_j }{\\partial w_{i, j}} = (a_j - y_j) x_i $$\n",
    "\n",
    "$$\\frac{\\partial \\mathcal{L} }{\\partial b_{j}} = \\frac{\\partial \\mathcal{L}}{\\partial z_j} \\frac{\\partial z_j }{\\partial b_{j}} = a_j - y_j $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorization for m training examples \n",
    "\n",
    "\n",
    "### 1. Forward propagation\n",
    "\n",
    "let's use the convention that the data matrix $X$ with shape $m \\times n$ has $m$ training examples and $n$ features for each example:\n",
    "\n",
    "$$\n",
    "X_{(m, n)}=\n",
    "\\begin{bmatrix} \n",
    "\\dots x^{(1)} \\dots \\\\\n",
    "\\vdots \\\\\n",
    "\\dots x^{(m)} \\dots \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$$W_{(n, 10)}=\n",
    "\\begin{bmatrix} \n",
    "\\vdots \\dots \\vdots \\\\w^{(1)} \\dots w^{(10)} \\\\ \\vdots \\dots \\vdots \\\\\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "$$Z_{(m, 10)} = X W$$\n",
    "\n",
    "$$A_{(m, 10)} = \\text{softmax}(Z_{(m, 10)})$$\n",
    "\n",
    "Also, we have $Y_{(m, 10)}$, then the cross entropy loss is:\n",
    "$$J = - \\frac{1}{m} || Y * \\log A ||_{F} = - \\frac{1}{m} \\sum\\limits_{i=1}^m \\sum\\limits_{j=1}^{10} Y_{i,j} \\log A_{i,j}$$\n",
    "\n",
    "### 2. Backward propagation\n",
    "$$dZ = Y - A$$\n",
    "$$dW = \\frac{1}{m} X^T (Y - A)$$\n",
    "$$db = \\frac{1}{m} (Y - A).sum(axis = 0)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_forward(X, W, b):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    X -- data matrix (m, n)\n",
    "    W -- weight matrix (n, num of class)\n",
    "    b -- bias vector (1, num of class)\n",
    "    \n",
    "    Return: \n",
    "    Z -- input of activation function (m, 10)\n",
    "    \"\"\"\n",
    "    \n",
    "    Z = np.dot(X, W) + b\n",
    "    \n",
    "    \n",
    "    \n",
    "    assert(Z.shape == (X.shape[0], W.shape[1]) )\n",
    "    \n",
    "    return Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def soft_max(Z):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    Z -- (m, num of class)\n",
    "    \n",
    "    Return:\n",
    "    A -- softmax matrix (m, num of class) \n",
    "    \"\"\"\n",
    "    exp_Z = np.exp(Z)\n",
    "    A = exp_Z / exp_Z.sum(axis = 1, keepdims = True) # sum along columns\n",
    "    \n",
    "    assert(A.shape == Z.shape )\n",
    "    \n",
    "    return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters(n, num_class):\n",
    "    \"\"\"\n",
    "    Return:\n",
    "    W -- (n, num of class)\n",
    "    b -- (1, num of class)\n",
    "    \"\"\"\n",
    "    np.random.seed(1)\n",
    "    W = np.random.randn(n, num_class) * 0.01\n",
    "    b = np.zeros((1, num_class))\n",
    "    \n",
    "    return W, b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Compute the cost function\n",
    "The cross entropy loss function for one example is $\\mathcal{L}(a, y) = -\\sum\\limits_{j = 1}^{10} a_{j} \\log y_{j}$. The overall loss is just the average of $\\mathcal{L}$ over all training examples: $$ J = \\frac{1}{m} \\sum\\limits_{i = 1}^{m} \\mathcal{L}(a^{(i)}, y^{(i)}) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0xab906d8>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.linspace(0.001, 1)\n",
    "y = - np.log(x)\n",
    "plt.plot(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If $a_j = 1$, the cost function want $y_j$ to be large while it heavily penalizes small $y_j$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cross_entropy_loss(A, Y):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    A -- prediction matrix of shape   (num of examples, num of class)\n",
    "    Y -- one-hot matrix of true class (num of examples, num of class)\n",
    "    Return:\n",
    "    lost (scalar)\n",
    "    \"\"\"\n",
    "    m = A.shape[0]\n",
    "    return -(Y * np.log(A)).sum() / m\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_propagation(X, A, Y):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    X -- data matrix shape:  (m, n)\n",
    "    A -- output of softmax:  (m, 10)\n",
    "    Y -- one-hot true labels:(m, 10)\n",
    "    \"\"\"\n",
    "    m = X.shape[0]\n",
    "    \n",
    "    dZ = A - Y\n",
    "    dW = 1/m * np.dot(X.T, dZ)\n",
    "    db = 1/m * np.sum(dZ, axis = 0, keepdims = True)\n",
    "    \n",
    "    return dW, db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now Let's verify the correctness of our backward propagation using gradient checking. The idea is to compare the analytical derivatives to the numerical derivatives using central difference. Let's just do this for weight matrix $W$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_check(W, dW, X, Y, epsilon = 1e-7):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    W --  current weight matrix (num of feature, 10)\n",
    "    dW -- analytical derivative matrix (num of feature, 10)\n",
    "    X --  data matrix (num of examples, num of feature)\n",
    "    Y --  one-hot label (num of examples, 10)\n",
    "    \n",
    "    Return:\n",
    "    difference\n",
    "    \"\"\"\n",
    "    gradApprox = np.zeros((dW.shape[0], dW.shape[1]))\n",
    "    for i in range(0, W.shape[0]):\n",
    "        for j in range(0, W.shape[1]):\n",
    "            W_plus = np.copy(W)\n",
    "            W_minus = np.copy(W)\n",
    "            \n",
    "            W_plus[i, j] = W_plus[i, j] + epsilon\n",
    "            W_minus[i, j] = W_minus[i, j] - epsilon\n",
    "            \n",
    "            Z_plus = linear_forward(X, W_plus, b)\n",
    "            A_plus = soft_max(Z_plus)\n",
    "            J_plus = compute_cross_entropy_loss(A_plus, Y)\n",
    "\n",
    "            Z_minus = linear_forward(X, W_minus, b)\n",
    "            A_minus = soft_max(Z_minus)\n",
    "            J_minus = compute_cross_entropy_loss(A_minus, Y)\n",
    "            \n",
    "            gradApprox[i, j] = (J_plus - J_minus) / (2*epsilon)\n",
    "            \n",
    "    # Compare gradients\n",
    "    numerator = np.linalg.norm(gradApprox - dW)\n",
    "    denominator = np.linalg.norm(dW) + np.linalg.norm(gradApprox)\n",
    "    difference = numerator / denominator\n",
    "    \n",
    "    if difference > 3e-7:\n",
    "        print (\"\\033[93m\" + \"There is a mistake in the backward propagation! difference = \" + str(difference) + \"\\033[0m\")\n",
    "    else:\n",
    "        print (\"\\033[92m\" + \"Your backward propagation works perfectly fine! difference = \" + str(difference) + \"\\033[0m\")\n",
    "    \n",
    "    return difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_feature = X_train.shape[1]\n",
    "num_class = 10\n",
    "\n",
    "W, b = initialize_parameters(num_feature, num_class)\n",
    "Z = linear_forward(X_train, W, b)\n",
    "A = soft_max(Z)\n",
    "dW, db = backward_propagation(X_train, A, Y_train_one_hot)\n",
    "\n",
    "#gradient_check(W, dW, X_train, Y_train_one_hot, epsilon = 1e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mclr_model(X, Y, num_iterations = 10000, learning_rate = 1.0, print_cost = False):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    X -- data matrix of shape:    (m, n)\n",
    "    Y -- one-hot labels of shape: (m, num of class)\n",
    "    \n",
    "    Return:\n",
    "    W, b -- parameters of the model\n",
    "    \"\"\"\n",
    "    \n",
    "    num_feature = X.shape[1]\n",
    "    num_class = 10\n",
    "    costs = []\n",
    "    \n",
    "    W, b = initialize_parameters(num_feature, num_class)\n",
    "    \n",
    "    \n",
    "    # loop gradient decent\n",
    "    for i in range(0, num_iterations):\n",
    "        Z = linear_forward(X, W, b)\n",
    "        A = soft_max(Z)\n",
    "        \n",
    "        cost = compute_cross_entropy_loss(A, Y)\n",
    "        \n",
    "        dW, db = backward_propagation(X, A, Y)\n",
    "        \n",
    "        W = W - learning_rate * dW\n",
    "        b = b - learning_rate * db\n",
    "    \n",
    "        if print_cost and i % 100 == 0:\n",
    "            print(\"Cost after iteration %i: %f\" % (i, cost))\n",
    "        \n",
    "        costs.append(cost)\n",
    "        \n",
    "    \n",
    "    # plot the cost\n",
    "    plt.plot(np.squeeze(costs))\n",
    "    plt.ylabel('cost')\n",
    "    plt.xlabel('iterations (per hundreds)')\n",
    "    plt.title(\"learning rate = \" + str(learning_rate))\n",
    "    plt.show()\n",
    "    \n",
    "    return W, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 2.329673\n",
      "Cost after iteration 100: 0.344579\n",
      "Cost after iteration 200: 0.309545\n",
      "Cost after iteration 300: 0.293013\n",
      "Cost after iteration 400: 0.282683\n",
      "Cost after iteration 500: 0.275327\n",
      "Cost after iteration 600: 0.269677\n",
      "Cost after iteration 700: 0.265121\n",
      "Cost after iteration 800: 0.261321\n",
      "Cost after iteration 900: 0.258072\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3XucXHV9//HXe2Z2cycXstCQgCEIgigKRoRaK16rtBVrsZW2Xmuprfxs/dmfD9FHq7W1D3+ttcpPK2KLaL1UxQsUsViLSqXlskFALgIRuYRrQhJy22R3Zz6/P853ZieTmZ1Nsmdnd8/7+XjMY2a+5zvnfM5Msu8558z5HkUEZmZmAKVeF2BmZtOHQ8HMzBocCmZm1uBQMDOzBoeCmZk1OBTMzKzBoWBTRtJ9kl7ao2XvkLSmF8s2m0kcClYIEbEwIu7tdR0AkkLSU3uw3GdLWidpV7p/9jh9T5B0taQnJa2X9BtTWav1jkPBZjxJ5V7XUCep0usa2pHUD1wGfAFYCnwOuCy1t/atpL5XAMuAc4EvSDpu6iq2XnEoWE9IKkl6j6SfSXpC0lclLWua/jVJj6ZvqtdIOrFp2iWSPiXpSkk7gReltk9K+rak7ZKul3RM02sa384n0Pflku5Ky/5HST+U9NYO6/EBSZdK+oKkbcCbJJ0q6X8kbZX0iKRP1P/4SromvfSWtEvrt1P7r0m6Ob3mvyWdNIlvN8AZQAX4WETsiYgLAAEvbtP3eOAI4B8iohoRVwPXAq+f5JpsGnIoWK+8A3g18EKyP0BbgE82Tf8OcCxwGHAT8MWW1/8O8CFgEfCj1HYO8Jdk34TXp+mdtO0raTlwKXA+cChwF/CLXdblrPSaJanOKvBOYDlwOvAS4I8BIuKX02uelXZpfUXSKcDFwB+mZX4auFzSnHYLk3RrCo92t3/sUOOJwK2x97g2t6b2fRbRoe0Znd4Amz0cCtYrfwi8LyI2RMQe4APA2fXdLxFxcURsb5r2LEmLm15/WURcGxG1iNid2r4RETdExCjZH+eO+8zH6XsmcHtEfCNNuwB4tMu6/E9EfCvVMhQR6yLiuogYjYj7yP7Iv3Cc1/8B8OmIuD59M/8csAc4rV3niDgpIpZ0uP1xh2UsBJ5saXuSLFRb/RR4HPg/kvokvTzVP3+cdbBZwqFgvfIU4Jv1b7jAnWTfsA+XVJb04bRraRtwX3rN8qbXP9hmns1/vHeR/SHspFPfI5rnnb5Zb+iyLnvVIuk4SVek3V/bgL9pqb3VU4B3NX/jB45MtUyWHcAhLW2HANtbO0bECNlW3K+SvU/vAr5K9/fBZgGHgvXKg8ArW77lzo2Ih8h2DZ0FvBRYDKxOr2nerZHX8L6PAKvqTySp+XkHrbV8iuzb9rERcQjwXtrvkql7EPhQy3sxPyK+3K6zpNvT8Yh2tws7LON24KS0PnUnpfZ9Vyji1oh4YUQcGhG/AqwBbhhnHWyWcChYr1wIfEjSUwAkDUg6K01bRLb75AmyXRZ/M4V1fRt4pqRXp11Zbwd+YT/nsQjYBuyQdDzwRy3THyP7I1v3GeBtkp6nzAJJvyqp3a4dIuLEdDyi3e1tHWr6AdmW2DskzZF0Xmq/ul1nSSdJmitpvqQ/A1YAl0xg3W2GcyhYr3wcuBz4rqTtwHXA89K0zwP3Aw8Bd6RpUyIiNgGvBf6WLJSeDgyShdRE/RnZ1s52sj/4X2mZ/gHgc2lX0W9FxCDZcYVPkB1wXw+86cDXYl8RMUy2S+gNwFbgLcCrUzuS3ivpO00veT3ZVtPjZAfKX5aO79gsJ19kx6wzSSWyfem/GxHf73U9ZnnzloJZC0m/ImlJ+klo/XjAlG2tmPWSQ8FsX6cDPwM2Ab9OtptlqLclmU0N7z4yM7MGbymYmVnDtBy8azzLly+P1atX97oMM7MZZd26dZsiYqBbvxkXCqtXr2ZwcLDXZZiZzSiS7p9IP+8+MjOzBoeCmZk1OBTMzKzBoWBmZg0OBTMza3AomJlZg0PBzMwaChMKdz26nY9+9y427fDov2ZmnRQmFO55fDsXXL2ezTuHe12Kmdm0VZhQULoaosf/MzPrrDihkK5MG7ld2tfMbOYrTiike28pmJl1VpxQkHcfmZl1U6BQyO5rTgUzs46KEwq9LsDMbAYoTih495GZWVfFCYV0718fmZl1VpxQqP8k1ZlgZtZR8UKht2WYmU1rxQmFxhnNjgUzs04KEwp4S8HMrKvChILPaDYz664woVDS2O+PzMysvcKEwtgZzb2tw8xsOitOKHjobDOzrooTCo3zFJwKZmadFCcU0r0jwcyss8KEAj6j2cysq8KEQuOYgrcVzMw6Kk4oeP+RmVlXxQmFdO9MMDPrrDih4OspmJl1VaBQyO59TMHMrLPChELJZzSbmXVVmFDAQ2ebmXVVmFDwRXbMzLrLLRQkHSnp+5LulHS7pD9p00eSLpC0XtKtkk7JrZ76A6eCmVlHlRznPQq8KyJukrQIWCfpPyLijqY+rwSOTbfnAZ9K95Ou8esjp4KZWUe5bSlExCMRcVN6vB24E1jZ0u0s4PORuQ5YImlFHvX4IjtmZt1NyTEFSauBk4HrWyatBB5ser6BfYNjkmrI7h0KZmad5R4KkhYCXwf+NCK2tU5u85J9/mxLOlfSoKTBjRs3HlgdjbGPzMysk1xDQVIfWSB8MSK+0abLBuDIpuergIdbO0XERRGxNiLWDgwMHGAtjXkd0OvNzIogz18fCfhn4M6I+GiHbpcDb0i/QjoNeDIiHsmrJvCWgpnZePL89dHzgdcDP5F0c2p7L3AUQERcCFwJnAmsB3YBb86rmJLHPjIz6yq3UIiIH9H+mEFznwDenlcNzbz7yMysO5/RbGZmDcUJBbz7yMysm+KEgofONjPrqjihkO69pWBm1llxQsHHFMzMuipMKPh6CmZm3RUmFDTuj2PNzAyKFArp3hsKZmadFSYUSr6egplZV4UJhfruo1qtt3WYmU1nxQkFD51tZtZVcULBYx+ZmXVVmFCocySYmXVWmFBo/CTVqWBm1lGBQsG/PjIz66Y4oZDufUjBzKyz4oSCxz4yM+uqOKHg6ymYmXVVmFAo+XoKZmZdFSYU6gcVas4EM7OOChMK9d1H3n9kZtZZcULBB5rNzLoqTiike28omJl1VpxQkK+8ZmbWTXFCId07EszMOitOKPg4s5lZV8UJBV9Pwcysq8KEAr6egplZV4UJhfoZzWZm1llhQqH+66OatxTMzDoqTiike2eCmVlnxQkFn9FsZtZVcULBQ2ebmXVVnFDw0NlmZl0VLxScCWZmHRUmFCqlbFVHq04FM7NOChMK5ZKQoFqr9boUM7NpqzChAFApiRFfes3MrKOChUKJqkPBzKyj3EJB0sWSHpd0W4fpZ0h6UtLN6fYXedVSVymJkap3H5mZdZLnlsIlwCu69PmviHh2un0wx1oA2D1a5bPX3scP796Y96LMzGak3EIhIq4BNuc1/wMxkn559NHv3tXjSszMpqdeH1M4XdItkr4j6cROnSSdK2lQ0uDGjQf/LX/YP0s1M2url6FwE/CUiHgW8P+Ab3XqGBEXRcTaiFg7MDBw0Ase9XEFM7O2ehYKEbEtInakx1cCfZKWT8WyfbDZzKy9noWCpF9QusiBpFNTLU9MxbJHvPvIzKytSl4zlvRl4AxguaQNwPuBPoCIuBA4G/gjSaPAEPC6mKJrZQ57S8HMrK3cQiEizuky/RPAJ/Ja/nhqPoHNzKytXv/6qCfKvmCzmVlbDgUzM2soZCiU5FAwM2unkKFQKTsUzMzaKVQorFo6DwBHgplZe4UKha+97XQAli3o73ElZmbT04RCQdJrJ9I23a1YPI9fPm4An7tmZtbeRLcUzp9g27RXls9TMDPrZNyT1yS9EjgTWCnpgqZJhwCjeRaWl7KvvmZm1lG3M5ofBgaBVwHrmtq3A+/Mq6g8lUs4FMzMOhg3FCLiFuAWSV+KiBEASUuBIyNiy1QUONnKJVGdmiGWzMxmnIkeU/gPSYdIWgbcAnxW0kdzrCs3JcnHFMzMOphoKCyOiG3Aa4DPRsRzgJfmV1Z+KiUx6lAwM2troqFQkbQC+C3gihzryV2pJB9TMDPrYKKh8EHgKuBnEXGjpDXAPfmVlZ+yRM3HFMzM2prQ9RQi4mvA15qe3wv8Zl5F5alS9paCmVknEz2jeZWkb0p6XNJjkr4uaVXexeWhJIeCmVknE9199FngcuAIYCXwb6ltxvFPUs3MOptoKAxExGcjYjTdLgEGcqwrN95SMDPrbKKhsEnS70kqp9vvAU/kWVheKiWfp2Bm1slEQ+EtZD9HfRR4BDgbeHNeReWp7PMUzMw6mtCvj4C/At5YH9oindn8EbKwmFFKJf8k1cysk4luKZzUPNZRRGwGTs6npHyV5S0FM7NOJhoKpTQQHtDYUpjoVsa0UimLCI+UambWzkT/sP898N+SLgWC7PjCh3KrKkf9lSwHR6o1yqVyj6sxM5teJnpG8+clDQIvJrvu/Wsi4o5cK8tJfzkLheFqjbl9DgUzs2YT3gWUQmBGBkGz+pbC8Gitx5WYmU0/Ez2mMGs0thQcCmZm+yhcKPSVx44pmJnZ3goXCt59ZGbWWXFDwVsKZmb7KF4o+JiCmVlHxQsF7z4yM+uocKEwdqDZZzSbmbUqXCiMHVOo9rgSM7Ppp3ChMC+dxTw07N1HZmatChcK8/uzUNg1PNrjSszMpp8Ch4J3H5mZtSpcKCyYkw33tNNbCmZm+8gtFCRdLOlxSbd1mC5JF0haL+lWSafkVUuzOZUSEgx5S8HMbB95bilcArxinOmvBI5Nt3OBT+VYS4MkFvRX2LnHoWBm1iq3UIiIa4DN43Q5C/h8ZK4DlkhakVc9zeb1lxka8e4jM7NWvTymsBJ4sOn5htS2D0nnShqUNLhx48aDXnClJEZ98pqZ2T56GQpq09b2L3VEXBQRayNi7cDAwEEvuCRRDYeCmVmrXobCBuDIpuergIenYsHlkqjVHApmZq16GQqXA29Iv0I6DXgyIh6ZigWXS8J7j8zM9jXhazTvL0lfBs4AlkvaALwf6AOIiAuBK4EzgfXALuDNedXSqiS8pWBm1kZuoRAR53SZHsDb81r+eMolUXUomJnto3BnNIMPNJuZdVLIUPCBZjOz9gobCt5SMDPbVyFDoSQfUzAza6eQoVAuiZq3FMzM9lHMUJC4dv0TvOHiG3pdipnZtFLIUCiltb7m7oMfR8nMbDYpZCiUS+2GXTIzs0KGQkkOBTOzdgoZCt5SMDNrr5ih4C0FM7O2ChkKJW8pmJm1VchQ8JaCmVl7hQyFUtNah09iMzNrKGYoNG0peLgLM7MxhQyF5l8fjfgSbGZmDcUMhaYtheFqrYeVmJlNL4UMheZfH406FMzMGgoZCiNNQeDdR2ZmYwoZCk8OjTQe7x6p9rASM7PppZCh8P5fP5E1yxcAeweEmVnRFTIUjl6+gL977UkAPLhlV4+rMTObPgoZCgBL5vcDcN6XftzjSszMpo/ChsLyBXN6XYKZ2bRT2FBYPL+Pl55wOAC7hkd7XI2Z2fRQ2FAAePHxhwGwbcihYGYGBQ+FRXMrAGzb7V8gmZmBQwGA7Q4FMzOg8KHQB8C23d59ZGYGBQ+FpfOzUNi4fU+PKzEzmx4KHQqrD13AIXMr/PiBrb0uxcxsWih0KJRK4qmHLeSBzTt7XYqZ2bRQ6FAAWLF4Ho88ubvXZZiZTQsOhcVzeWjLkK+rYGaGQ4GTjlzCntEadz6yvdelmJn1XOFD4bmrlwJw432be1yJmVnvFT4UViyex8ol8xwKZmY4FAA49ehl3HjfFiJ8aU4zK7ZcQ0HSKyTdJWm9pPe0mf4mSRsl3Zxub82znk7Wrl7Kph17uP8JX3DHzIqtkteMJZWBTwIvAzYAN0q6PCLuaOn6lYg4L686JuK5q5cBcMN9m1mdLtNpZlZEeW4pnAqsj4h7I2IY+FfgrByXd8CeOrCQxfP6GPRxBTMruDxDYSXwYNPzDamt1W9KulXSpZKOzLGejkolcerRy7h2/RM+rmBmhZZnKKhNW+tf3H8DVkfEScD3gM+1nZF0rqRBSYMbN26c5DIzL3raYTy0dYi7H9uRy/zNzGaCPENhA9D8zX8V8HBzh4h4IiLqQ5R+BnhOuxlFxEURsTYi1g4MDORSbP0qbN+787Fc5m9mNhPkGQo3AsdKOlpSP/A64PLmDpJWND19FXBnjvWM6xcWz+UZKw/h6p8+3qsSzMx6LrdQiIhR4DzgKrI/9l+NiNslfVDSq1K3d0i6XdItwDuAN+VVz0S85PjDuemBLTyxw9dXMLNiyvU8hYi4MiKOi4hjIuJDqe0vIuLy9Pj8iDgxIp4VES+KiJ/mWU83L3v64UTAZTc/3L2zmdks5DOamzxj5WKeu3opF11zLzv2+BKdZlY8DoUW5595Ao9t3827L72Fas0/TzWzYnEotDjlqKW878wTuPInj/IHnx9ky87hXpdkZjZlHAptvPUFa/irs07kR/ds4sV//wP+5br7fREeMysEh0IHrz99NZed93yOO3wRf/6t2zjjIz/gkmt/zq5hH2sws9lLM21Yh7Vr18bg4OCULS8i+N6dj3PhD3/Guvu3sGhuhV876QjOfs5KTjlqKVK7E7fNzKYXSesiYm3Xfg6FiRu8bzNfuv4BvnPbowyNVFm5ZB4vPv4wXnLCYZy25lDm9pV7UpeZWTcOhRzt2DPKv9/2KFfd/ig/umcTQyNV5lRKnHzUEk49+lCed/QyTj5qCfP7cxuZ3MxsvzgUpsjukSr/c+8T/Nfdm7jxvs3c/vCT1AJKgjUDCznxiEN4+opDOPGIxZywYhHLFvR7l5OZTbmJhoK/yh6kuX1lXvS0w3jR07IB9bbvHmHd/Vv48QNbuf3hbdz48817nSG9eF4fawYWsGb5QtYMLOCYgQUctWwBK5fM45B5FQeGmfWUtxSmwOadw9z+8JPc/dgO7t24g3s37uTeTTt4bNveYywtnFPhiCVzWblkHkc0bnMZWDiXgUVzGFg0hyXz+iiVHBxmtn+8pTCNLFvQzwuOHeAFx+497PeOPaP8fONONmzZxUNbh9iwZYiHtw7x0NYhbn5wK1t2jewzr0pJLF84h+WL+hlYmAXFoQuzsFg6v5/F87P7JfP7stu8fvor/uWxmU2MQ6GHFs6p8MxVi3nmqsVtp+/cM8qj23azafseNu7Yw8btTbcd2e32h7exeecwo+MMybGgv8ySFBSL5/WxcE6FhXMrLEr3C+f0sWhuhUVzK9m0xvS+NL3iYDErCIfCNLZgToVjBhZyzMDCcftFBDuHq2zdNczWXSNs3TXCll3DbB0aYevO7H5LmrZ99wgPbN7F9t2j7NiT3SYyxlN/ucS8/jLz+srM7y8zrz+7n5uez++v7Du9L7uf119hfmqf01dmTqXE3L4ScyrZ43rbnErJx1TMesyhMAtIanzDX7V0/14bEeweqbF9z0gWFCkstjfus/Zdw1WGhrP7XSNVdg9X2TVcZdvuUR7btpuhkSpDqW1opMqBHqrqT+Ewp1JOwZHCo6+1vR4oY4/7yiX6KyX6yqKvnJ432lJ7JWtrPG+Zvnf/rM1BZUXiUCg4SenbfJnDFk3OPCOCPaO1LECGRxlKQbFruMqe0Rq7R7L7PfX70Rp7RqvsHsnu94yMtWX9xtq37hoee81Ild1N8xlvF9rBaA6ZLGiycOkrl6iURKUsKqWxx33lEuXS3m3Zfbv+HfrsNa2lT6k0No+28xblNP9SSZQlyqV0kyiX924rCQefNTgUbNJJYm5ftmtp2YL+KVtuRDBSDYarNUZGa4xUa9njamSPU1vjeeqX9akxMhpjj1O/sdfUGvNubhutBqO1bH7VWjBaDXaOjjKaHo/WamOPq+lxbd/HvR6lvR4YpRJUSiVKSm2lEuUSHcIkC6HsdVkYlZoDqEPbXvNo6lNp01bvJ2U1lNKy6vVJafkitY8/rVyiqT1b3/py6uHYaVpJYzUpLaPe1pjeVFvztHo9M4FDwWYNSfRXlB0Un9PravZPrR4QzSFSy0KnmkKnbdC06TNSrVGLoFqDaq2W3UdQrdaoxtiyapHNoxqxV1u11nSLoJr6tGtrfd1oLQvSjvNKj9u9rrWt10GZh04BM7HwgXNOPYq3vmBNrjU6FMymgVJJ9JdEvwcuboimcKjF3mFRq4dHBBGk9r0fZ7em5zWaXpOFZi0FWy2y4KyNMy06LL/5+Xi1tS6n8byWzXv85WT1DCzK/9uOQ8HMpiWl3VM2tfy1xMzMGhwKZmbW4FAwM7MGh4KZmTU4FMzMrMGhYGZmDQ4FMzNrcCiYmVnDjLvymqSNwP0H+PLlwKZJLGcm8DoXg9e5GA5mnZ8SEQPdOs24UDgYkgYncjm62cTrXAxe52KYinX27iMzM2twKJiZWUPRQuGiXhfQA17nYvA6F0Pu61yoYwpmZja+om0pmJnZOBwKZmbWUJhQkPQKSXdJWi/pPb2uZ7JIOlLS9yXdKel2SX+S2pdJ+g9J96T7paldki5I78Otkk7p7RocGEllST+WdEV6frSk69P6fkVSf2qfk56vT9NX97LugyFpiaRLJf00fd6nz+bPWdI707/p2yR9WdLc2fg5S7pY0uOSbmtq2+/PVdIbU/97JL3xQOspRChIKgOfBF4JPB04R9LTe1vVpBkF3hURJwCnAW9P6/Ye4D8j4ljgP9NzyN6DY9PtXOBTU1/ypPgT4M6m5/8X+Ie0vluA30/tvw9siYinAv+Q+s1UHwf+PSKOB55Ftv6z8nOWtBJ4B7A2Ip4BlIHXMTs/50uAV7S07dfnKmkZ8H7gecCpwPvrQbLfIl0TdDbfgNOBq5qenw+c3+u6clrXy4CXAXcBK1LbCuCu9PjTwDlN/Rv9ZsoNWJX+o7wYuAIQ2VmeldbPG7gKOD09rqR+6vU6HMA6HwL8vLX22fo5AyuBB4Fl6XO7AviV2fo5A6uB2w70cwXOAT7d1L5Xv/25FWJLgbF/YHUbUtuskjaZTwauBw6PiEcA0v1hqdtseC8+BrwbqKXnhwJbI2I0PW9ep8b6pulPpv4zzRpgI/DZtNvsnyQtYJZ+zhHxEPAR4AHgEbLPbR2z/3Ou29/PddI+76KEQrurf8+q3+JKWgh8HfjTiNg2Xtc2bTPmvZD0a8DjEbGuublN15jAtJmkApwCfCoiTgZ2MrZLoZ0Zvd5p18dZwNHAEcACsl0nrWbb59xNp/WctPUvSihsAI5ser4KeLhHtUw6SX1kgfDFiPhGan5M0oo0fQXweGqf6e/F84FXSboP+FeyXUgfA5ZIqqQ+zevUWN80fTGweSoLniQbgA0RcX16filZSMzWz/mlwM8jYmNEjADfAH6R2f851+3v5zppn3dRQuFG4Nj0y4V+sgNWl/e4pkkhScA/A3dGxEebJl0O1H+B8EayYw319jekXzGcBjxZ30ydCSLi/IhYFRGryT7HqyPid4HvA2enbq3rW38fzk79Z9w3yIh4FHhQ0tNS00uAO5ilnzPZbqPTJM1P/8br6zurP+cm+/u5XgW8XNLStJX18tS2/3p9gGUKD+ScCdwN/Ax4X6/rmcT1+iWyzcRbgZvT7Uyy/an/CdyT7pel/iL7JdbPgJ+Q/bqj5+txgOt+BnBFerwGuAFYD3wNmJPa56bn69P0Nb2u+yDW99nAYPqsvwUsnc2fM/CXwE+B24B/AebMxs8Z+DLZcZMRsm/8v38gnyvwlrT+64E3H2g9HubCzMwairL7yMzMJsChYGZmDQ4FMzNrcCiYmVmDQ8HMzBocCpYLSf+d7ldL+p1Jnvd72y0rL5JeLekvcpr3jpzme0Z9BNmDmMclks4eZ/p5kt58MMuw6cehYLmIiF9MD1cD+xUKaVTb8ewVCk3Lysu7gX882JlMYL1y13Q28GS4mGwkU5tFHAqWi6ZvwB8GXiDp5jQ+flnS30m6MY0H/4ep/xnKrgvxJbKTcpD0LUnr0pj656a2DwPz0vy+2LysdJbn36Xx938i6beb5v0DjV2L4IvpLFkkfVjSHamWj7RZj+OAPRGxKT2/RNKFkv5L0t1pLKb69R0mtF5tlvEhSbdIuk7S4U3LObupz46m+XVal1ekth8Br2l67QckXSTpu8Dnx6lVkj6R3o9vMzYIW9v3KSJ2AfdJOnUi/yZsZpjMbw1m7bwH+LOIqP/xPJfs1PznSpoDXJv+WEE2DvwzIuLn6flbImKzpHnAjZK+HhHvkXReRDy7zbJeQ3bW77OA5ek116RpJwMnko0Hcy3wfEl3AL8BHB8RIWlJm3k+H7ippW018ELgGOD7kp4KvGE/1qvZAuC6iHifpL8F/gD46zb9mrVbl0HgM2RjQa0HvtLymucAvxQRQ+N8BicDTwOeCRxONqzExcrG6u/0Pg0CLyA7i9hmAW8p2FR7OdnYLTeTDfF9KNkFQwBuaPnD+Q5JtwDXkQ32dSzj+yXgyxFRjYjHgB8Cz22a94aIqJENBbIa2AbsBv5J0muAXW3muYJsyOpmX42IWkTcA9wLHL+f69VsmOxaAZANDb26yzp2WpfjyQaQuyeyYQq+0PKayyNiKD3uVOsvM/b+PQxcnfqP9z49TjaKqc0S3lKwqSbgf0XEXoN1STqDbDjo5ucvJbtwyi5JPyAb36bbvDvZ0/S4SnahltG06+MlZIPrnUf2TbvZENmIm81ax4apD13cdb3aGImxsWaqjP2fHCV9aUu7h/rHW5cOdTVrrqFTrWe2m0eX92ku2Xtks4S3FCxv24FFTc+vAv5I2XDfSDpO2cViWi0mu7ziLknHk11qtG6k/voW1wC/nfaZD5B98+24W0PZNSgWR8SVwJ+S7XpqdSfw1Ja210oqSTqGbIC2u/ZjvSbqPrJdPpBdV6Dd+jb7KXB0qgmyK3F10qnWa4DXpfdvBfCiNH289+k4sgHrbJbwloLl7VZgNO0GuoTsOsOrgZvSN+CNwKvbvO7fgbdJupXsj+51TdMuAm6VdFNkw2bXfZPsEo23kH3jfXdEPJpCpZ1FwGWS5pJ9e35nmz7XAH8vSU3f6O8i2zV1OPC2iNgt6Z/k/7nhAAAAlklEQVQmuF4T9ZlU2w1ko2SOt7VBquFc4NuSNgE/Ap7RoXunWr9JtgXwE7IRhX+Y+o/3Pj2fbDRTmyU8SqpZF5I+DvxbRHxP0iVkw3Vf2uOyek7SycD/jojX97oWmzzefWTW3d8A83tdxDS0HPjzXhdhk8tbCmZm1uAtBTMza3AomJlZg0PBzMwaHApmZtbgUDAzs4b/DxE5KxY348l8AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "W, b = mclr_model(X_train, Y_train_one_hot, num_iterations = 1000, learning_rate = 0.9, print_cost = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(W, b, X):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    W -- the learned weight matrix (num_feature, num_class)\n",
    "    b -- the learned bias   matrix (1, num_class)\n",
    "    X -- input data (m, num_feature)\n",
    "    \n",
    "    Return:\n",
    "    prediction -- softmax vector (1, num_feature)\n",
    "    \"\"\"\n",
    "    A = soft_max(linear_forward(X, W, b))\n",
    "    \n",
    "    prediction = np.argmax(A, axis = 1)\n",
    "    \n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training accuracy\n",
    "Y_train_hat = predict(W, b, X_train)\n",
    "\n",
    "m = X_train.shape[0]\n",
    "num_correct = m - np.count_nonzero((np.squeeze(Y_train) - Y_train_hat))\n",
    "\n",
    "print(\"Training accuracy: %f\" % float(num_correct / m * 100.0) + \"%\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing accuracy\n",
    "Y_test_hat = predict(W, b, X_test)\n",
    "\n",
    "m = X_test.shape[0]\n",
    "num_correct = m - np.count_nonzero((np.squeeze(Y_test) - Y_test_hat))\n",
    "\n",
    "print(\"Testing accuracy: %f\" % float(num_correct / m * 100.0) + \"%\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK! We got nearly 90% of accuracy for both training and testing data using the simple linear classifier. In the next notebook, we will build a deeper network which includes more non-linear units to improve the accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix: Math for binary logistic regression\n",
    "### For one example $x = \\{x_1, \\dots, x_n \\}$, \n",
    "we have $w = \\{w_1, \\dots, w_n \\}$, and $b$\n",
    "\n",
    "$$z = \\sum\\limits_{i=1}^{n} w_i x_i + b$$\n",
    "\n",
    "$$a = \\sigma(z) = \\frac{1}{1+e^{-z}}$$\n",
    "\n",
    "Then, the cost function is \n",
    "$$ \\mathcal{L}(a, y) =  - y  \\log(a) - (1-y )  \\log(1-a)$$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Now we derive the derivatives for gradient decent:\n",
    "\n",
    "$$da = -\\frac{y}{a} +\\frac{1-y}{1-a}$$\n",
    "$$dz = da*a*(1-a) = a - y$$\n",
    "$$dw_i = dz * x = (a - y)*x_i$$\n",
    "$$db = dz = a - y$$\n",
    "\n",
    "### For vectorization and m training examples:\n",
    "\n",
    "Given \n",
    "$$X_{(m, n)}\n",
    "=\n",
    "\\begin{bmatrix} \n",
    "\\dots x^{(1)} \\dots \\\\\n",
    "\\vdots \\\\\n",
    "\\dots x^{(m)} \\dots \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "we need to have\n",
    "$$W_{(n, 1)}\n",
    "=\n",
    "\\begin{bmatrix} \n",
    "w_1  \\\\ \\vdots \\\\ w_n \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$$b_{(m, 1)}\n",
    "=\n",
    "\\begin{bmatrix} \n",
    "b_1  \\\\ \\vdots \\\\ b_m \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "#### 1. Forward propagation:\n",
    "\n",
    "$$Z = X W + b$$\n",
    "$$A = \\sigma(Z) $$\n",
    "\n",
    "\n",
    "#### 2. The cost is then computed by summing over all training examples:\n",
    "\n",
    "$$ J = \\frac{1}{m} ||\\mathcal{L}(A, Y)||_F = \\frac{1}{m} \\sum_{i=1}^m \\mathcal{L}(a^{(i)}, y^{(i)})$$\n",
    "\n",
    "#### 3. Back propagation:\n",
    "$$dZ = A - Y $$\n",
    "$$ \\frac{\\partial J}{\\partial w} = \\frac{1}{m}X^T(A-Y)$$\n",
    "$$ \\frac{\\partial J}{\\partial b} = \\frac{1}{m} (A-Y).sum() = \\frac{1}{m} \\sum_{i=1}^m (a^{(i)}-y^{(i)})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
