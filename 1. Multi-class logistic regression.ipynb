{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Softmax logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples = 31500\n",
      "Number of testing examples = 10500\n",
      "Number of features = 784\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"data/MNIST_train.csv\").values\n",
    "\n",
    "X_data = data[:, 1:]\n",
    "Y_data = data[:, [0]]\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_data, Y_data, random_state = 0)\n",
    "\n",
    "print(\"Number of training examples = \" + str(X_train.shape[0]) )\n",
    "print(\"Number of testing examples = \" + str(X_test.shape[0]) )\n",
    "print(\"Number of features = \" +  str(X_train.shape[1]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'label is [5]')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "index = 10\n",
    "sampleImg = np.reshape(X_train[index, :], [28, 28])\n",
    "\n",
    "ax = plt.imshow(sampleImg)\n",
    "plt.title(\"label is \" + str(Y_train[index, :]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple standardization for images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train / 255\n",
    "X_test = X_test / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert labels to its one-hot encoding for defining the loss function of softmax classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_matrix(Y, num_class):\n",
    "    \"\"\"\n",
    "    Convert an array of Y to its one_hot_matrix\n",
    "    \n",
    "    Arguments:\n",
    "    Y -- array (number of examples, 1)\n",
    "    num_class -- num of classes\n",
    "    \n",
    "    Return:\n",
    "    Y_one_hot -- (number of examples, num_class)\n",
    "    \"\"\"\n",
    "    Y_one_hot = np.zeros((Y.shape[0], num_class))\n",
    "    Y_one_hot[np.arange(Y.shape[0]), Y.T] = 1\n",
    "    \n",
    "    return Y_one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Letter 9 converted to [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "Y_train_one_hot = one_hot_matrix(Y_train, 10)\n",
    "Y_test_one_hot = one_hot_matrix(Y_test, 10)\n",
    "\n",
    "index = 2\n",
    "print(\"Letter \" + str(Y_train[index, 0]) + \" converted to \" + str(Y_train_one_hot[index, :]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Math for one training example\n",
    "###  1. Forward propagation\n",
    "\n",
    "We treate the softmax classification problem as a 1-layer neural network with 10 nerons (add image). Each neural is just a linear combination of all input features, and the softmax activation function takes effect for all neurons.\n",
    "\n",
    "For one example $\\{x_1, ..., x_{n} \\}$ (use column vectors in the following for legibility):\n",
    "\n",
    "#### Linear forward\n",
    "\n",
    "$$\n",
    "Z\n",
    "=\n",
    "\\begin{bmatrix} \n",
    "z_1 \\\\\n",
    "\\vdots \\\\\n",
    "z_j \\\\\n",
    "\\vdots \\\\\n",
    "z_{10} \\\\\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix} \n",
    "\\sum\\limits_{i=1}^{n} w_{i, 1} x_{i} \\\\\n",
    "\\vdots \\\\\n",
    "\\sum\\limits_{i=1}^{n} w_{i, j} x_{i} \\\\\n",
    "\\vdots \\\\\n",
    "\\sum\\limits_{i=1}^{n} w_{i, 10} x_{i} \\\\\n",
    "\\end{bmatrix}\n",
    "+\n",
    "\\begin{bmatrix} \n",
    "b_1 \\\\\n",
    "\\vdots \\\\\n",
    "b_j \\\\\n",
    "\\vdots \\\\\n",
    "b_{10} \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "#### Softmax\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix} \n",
    "z_1 \\\\\n",
    "\\vdots \\\\\n",
    "z_{10} \\\\\n",
    "\\end{bmatrix}\n",
    "\\Rightarrow \n",
    "\\begin{bmatrix} \n",
    "\\frac{e^{z_1} }{\\sum\\limits_{k = 1}^{10} e^{z_k} } \\\\\n",
    "\\vdots \\\\\n",
    "\\frac{e^{z_10} }{\\sum\\limits_{k = 1}^{10} e^{z_k} } \\\\\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix} \n",
    "a_1 \\\\\n",
    "\\vdots \\\\\n",
    "a_{10} \\\\\n",
    "\\end{bmatrix}\n",
    "=\n",
    "a\n",
    "$$\n",
    "\n",
    "\n",
    "### 2. Cross entropy loss\n",
    "\n",
    "\n",
    "$$\\mathcal{L}(a, y) = -\\sum\\limits_{j =1} ^{10} y_{j} \\log a_{j}$$\n",
    "\n",
    "### 3. Backward propagation\n",
    "\n",
    "#### 1. Derivative of linear function\n",
    "\n",
    "$$\\frac{\\partial z_j }{\\partial w_{i, j}} =  x_i $$\n",
    "$$\\frac{\\partial z_j }{\\partial b_{j}} =  1 $$\n",
    "\n",
    "\n",
    "#### 2. Derivative of the softmax function\n",
    "\n",
    "Let $\\Omega =  \\sum\\limits_{k = 1}^{10} e^{z_k}$, let compute the partial derivatives for the Jacobian matrix (10 x 10) $\\frac{\\partial a_p}{\\partial z_q}$:\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "\\text{if} \\; p = q :& \\frac{\\partial a_p}{\\partial z_p} = \\frac{\\partial \\frac{e^{z_p}}{\\Omega}}{\\partial z_p} = \\frac{e^{z_p}\\Omega - e^{z_p}e^{z_p}}{\\Omega^2} = \\frac{e^{z_p}}{\\Omega}\\frac{\\Omega - e^{z_p}}{\\Omega} = \\frac{e^{z_p}}{\\Omega}(1-\\frac{e^{z_p}}{\\Omega}) =  y_p (1 - y_p)\\\\\n",
    "\\text{if} \\; p \\neq q :& \\frac{\\partial y_p}{\\partial z_q} = \\frac{\\partial \\frac{e^{z_p}}{\\Omega}}{\\partial z_q} = \\frac{0 - e^{z_p}e^{z_q}}{\\Omega^2} = -\\frac{e^{z_p}}{\\Omega} \\frac{e^{z_1}}{\\Omega} = -y_p y_q\n",
    "\\end{split}$$\n",
    "\n",
    "#### 3. Derivative of the cross entropy loss for the softmax function\n",
    "$$\\begin{split}\n",
    "\\frac{\\partial \\mathcal{L}}{\\partial z_i} & = - \\sum_{j=1}^{10} \\frac{\\partial y_j log(a_j)}{\\partial z_i}{} =\n",
    "- \\sum_{j=1}^{10} y_j \\frac{\\partial log(a_j)}{\\partial z_i} = - \\sum_{j=1}^{10} y_j \\frac{1}{a_j} \\frac{\\partial a_j}{\\partial z_i} \\\\\n",
    "& = - \\frac{y_i}{a_i} \\frac{\\partial a_i}{\\partial z_i} - \\sum_{j \\neq i}^{10} \\frac{y_j}{a_j} \\frac{\\partial a_j}{\\partial z_i}\n",
    "= - \\frac{y_i}{a_i} a_i (1-a_i) - \\sum_{j \\neq i}^{10} \\frac{y_j}{a_j} (-a_j a_i) \\\\\n",
    "& = - y_i + y_i a_i + \\sum_{j \\neq i}^{10} y_j a_i = - y_i + \\sum_{j = 1}^{10} y_j a_i\n",
    "= -y_i + a_i \\sum_{j = 1}^{10} y_j \\\\\n",
    "& = a_i - y_i\n",
    "\\end{split}$$\n",
    "\n",
    "#### 3. Derivative of the cross entropy loss for $w$ and $b$\n",
    "\n",
    "$$\\frac{\\partial \\mathcal{L} }{\\partial w_{i, j}} = \\frac{\\partial \\mathcal{L}}{\\partial z_j} \\frac{\\partial z_j }{\\partial w_{i, j}} = (a_j - y_j) x_i $$\n",
    "\n",
    "$$\\frac{\\partial \\mathcal{L} }{\\partial b_{j}} = \\frac{\\partial \\mathcal{L}}{\\partial z_j} \\frac{\\partial z_j }{\\partial b_{j}} = a_j - y_j $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorization for m training examples \n",
    "\n",
    "\n",
    "### 1. Forward propagation\n",
    "let's use the convention that the data matrix $X$ with shape $m \\times n$ has $m$ training examples and $n$ features for each example:\n",
    "\n",
    "$$\n",
    "X_{(m, n)}\n",
    "=\n",
    "\\begin{bmatrix} \n",
    "\\dots x^{(1)} \\dots \\\\\n",
    "\\vdots \\\\\n",
    "\\dots x^{(m)} \\dots \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$$\n",
    "W_{(n, 10)}\n",
    "=\n",
    "\\begin{bmatrix} \n",
    "\\vdots \\dots \\vdots \\\\w^{(1)} \\dots w^{(10)} \\\\ \\vdots \\dots \\vdots \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$$\n",
    "Z_{(m, 10)} = X W\n",
    "$$\n",
    "\n",
    "$$\n",
    "A_{(m, 10)} = \\text{softmax}(Z_{(m, 10)})\n",
    "$$\n",
    "\n",
    "Also, we have $Y_{(m, 10)}$, then the cross entropy loss is:\n",
    "$$\n",
    "J = - \\frac{1}{m} || Y * \\log A ||_{F} = - \\frac{1}{m} \\sum\\limits_{i=1}^m \\sum\\limits_{j=1}^{10} Y_{i,j} \\log A_{i,j}\n",
    "$$\n",
    "\n",
    "### 2. Backward propagation\n",
    "$$\n",
    "dZ = Y - A\n",
    "$$\n",
    "$$\n",
    "dW = \\frac{1}{m} X^T (Y - A)\n",
    "$$\n",
    "$$\n",
    "db = \\frac{1}{m} (Y - A).sum(axis = 0)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_forward(X, W, b):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    X -- data matrix (m, n)\n",
    "    W -- weight matrix (n, num of class)\n",
    "    b -- bias vector (1, num of class)\n",
    "    \n",
    "    Return: \n",
    "    Z -- input of activation function (m, 10)\n",
    "    \"\"\"\n",
    "    \n",
    "    Z = np.dot(X, W) + b\n",
    "    \n",
    "    \n",
    "    \n",
    "    assert(Z.shape == (X.shape[0], W.shape[1]) )\n",
    "    \n",
    "    return Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def soft_max(Z):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    Z -- (m, num of class)\n",
    "    \n",
    "    Return:\n",
    "    A -- softmax matrix (m, num of class) \n",
    "    \"\"\"\n",
    "    exp_Z = np.exp(Z)\n",
    "    A = exp_Z / exp_Z.sum(axis = 1, keepdims = True) # sum along columns\n",
    "    \n",
    "    assert(A.shape == Z.shape )\n",
    "    \n",
    "    return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters(n, num_class):\n",
    "    \"\"\"\n",
    "    Return:\n",
    "    W -- (n, num of class)\n",
    "    b -- (1, num of class)\n",
    "    \"\"\"\n",
    "    np.random.seed(1)\n",
    "    W = np.random.randn(n, num_class)\n",
    "    b = np.zeros((1, num_class))\n",
    "    \n",
    "    return W, b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Compute the cost function\n",
    "The cross entropy loss function for one example is $\\mathcal{L}(a, y) = -\\sum\\limits_{j = 1}^{10} a_{j} \\log y_{j}$. The overall loss is just the average of $\\mathcal{L}$ over all training examples: $$J = \\frac{1}{m} \\sum\\limits_{i = 1}^{m} \\mathcal{L}(a^{(i)}, y^{(i)}) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0xab8f6d8>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.linspace(0.001, 1)\n",
    "y = - np.log(x)\n",
    "plt.plot(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If $a_j = 1$, the cost function want $y_j$ to be large while it heavily penalizes small $y_j$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cross_entropy_loss(A, Y):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    A -- prediction matrix of shape   (num of examples, num of class)\n",
    "    Y -- one-hot matrix of true class (num of examples, num of class)\n",
    "    Return:\n",
    "    lost (scalar)\n",
    "    \"\"\"\n",
    "    m = A.shape[0]\n",
    "    return -(Y * np.log(A)).sum() / m\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_propagation(X, A, Y):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    X -- data matrix shape:  (m, n)\n",
    "    A -- output of softmax:  (m, 10)\n",
    "    Y -- one-hot true labels:(m, 10)\n",
    "    \"\"\"\n",
    "    m = X.shape[0]\n",
    "    \n",
    "    dZ = A - Y\n",
    "    dW = 1/m * np.dot(X.T, dZ)\n",
    "    db = 1/m * np.sum(dZ, axis = 0, keepdims = True)\n",
    "    \n",
    "    return dW, db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now Let's verify the correctness of our backward propagation using gradient checking. The idea is to compare the analytical derivatives to the numerical derivatives using central difference. Let's just do this for weight matrix $W$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_check(W, dW, X, Y, epsilon = 1e-7):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    W --  current weight matrix (num of feature, 10)\n",
    "    dW -- analytical derivative matrix (num of feature, 10)\n",
    "    X --  data matrix (num of examples, num of feature)\n",
    "    Y --  one-hot label (num of examples, 10)\n",
    "    \n",
    "    Return:\n",
    "    difference\n",
    "    \"\"\"\n",
    "    gradApprox = np.zeros((dW.shape[0], dW.shape[1]))\n",
    "    for i in range(0, W.shape[0]):\n",
    "        for j in range(0, W.shape[1]):\n",
    "            W_plus = np.copy(W)\n",
    "            W_minus = np.copy(W)\n",
    "            \n",
    "            W_plus[i, j] = W_plus[i, j] + epsilon\n",
    "            W_minus[i, j] = W_minus[i, j] - epsilon\n",
    "            \n",
    "            Z_plus = linear_forward(X, W_plus, b)\n",
    "            A_plus = soft_max(Z_plus)\n",
    "            J_plus = compute_cross_entropy_loss(A_plus, Y)\n",
    "\n",
    "            Z_minus = linear_forward(X, W_minus, b)\n",
    "            A_minus = soft_max(Z_minus)\n",
    "            J_minus = compute_cross_entropy_loss(A_minus, Y)\n",
    "            \n",
    "            gradApprox[i, j] = (J_plus - J_minus) / (2*epsilon)\n",
    "            \n",
    "    # Compare gradients\n",
    "    numerator = np.linalg.norm(gradApprox - dW)\n",
    "    denominator = np.linalg.norm(dW) + np.linalg.norm(gradApprox)\n",
    "    difference = numerator / denominator\n",
    "    \n",
    "    if difference > 3e-7:\n",
    "        print (\"\\033[93m\" + \"There is a mistake in the backward propagation! difference = \" + str(difference) + \"\\033[0m\")\n",
    "    else:\n",
    "        print (\"\\033[92m\" + \"Your backward propagation works perfectly fine! difference = \" + str(difference) + \"\\033[0m\")\n",
    "    \n",
    "    return difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mYour backward propagation works perfectly fine! difference = 2.545963816174567e-07\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.545963816174567e-07"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_feature = X_train.shape[1]\n",
    "num_class = 10\n",
    "\n",
    "W, b = initialize_parameters(num_feature, num_class)\n",
    "Z = linear_forward(X_train, W, b)\n",
    "A = soft_max(Z)\n",
    "dW, db = backward_propagation(X_train, A, Y_train_one_hot)\n",
    "\n",
    "gradient_check(W, dW, X_train, Y_train_one_hot, epsilon = 1e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mclr_model(X, Y, num_iterations = 10000, learning_rate = 1.0, print_cost = False):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    X -- data matrix of shape:    (m, n)\n",
    "    Y -- one-hot labels of shape: (m, num of class)\n",
    "    \n",
    "    Return:\n",
    "    W, b -- parameters of the model\n",
    "    \"\"\"\n",
    "    \n",
    "    num_feature = X.shape[1]\n",
    "    num_class = 10\n",
    "    costs = []\n",
    "    \n",
    "    W, b = initialize_parameters(num_feature, num_class)\n",
    "    \n",
    "    \n",
    "    # loop gradient decent\n",
    "    for i in range(0, num_iterations):\n",
    "        Z = linear_forward(X, W, b)\n",
    "        A = soft_max(Z)\n",
    "        \n",
    "        cost = compute_cross_entropy_loss(A, Y)\n",
    "        \n",
    "        dW, db = backward_propagation(X, A, Y)\n",
    "        \n",
    "        W = W - learning_rate * dW\n",
    "        b = b - learning_rate * db\n",
    "    \n",
    "        if print_cost and i % 100 == 0:\n",
    "            print(\"Cost after iteration %i: %f\" % (i, cost))\n",
    "        \n",
    "        costs.append(cost)\n",
    "        \n",
    "    \n",
    "    # plot the cost\n",
    "    plt.plot(np.squeeze(costs))\n",
    "    plt.ylabel('cost')\n",
    "    plt.xlabel('iterations (per hundreds)')\n",
    "    plt.title(\"learning rate = \" + str(learning_rate))\n",
    "    plt.show()\n",
    "    \n",
    "    return W, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 17.274049\n",
      "Cost after iteration 100: 1.023462\n",
      "Cost after iteration 200: 0.773471\n",
      "Cost after iteration 300: 0.663792\n",
      "Cost after iteration 400: 0.596771\n",
      "Cost after iteration 500: 0.550217\n",
      "Cost after iteration 600: 0.515490\n",
      "Cost after iteration 700: 0.488296\n",
      "Cost after iteration 800: 0.466218\n",
      "Cost after iteration 900: 0.447800\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "W, b = mclr_model(X_train, Y_train_one_hot, num_iterations = 1000, learning_rate = 0.9, print_cost = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(W, b, X):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    W -- the learned weight matrix (num_feature, num_class)\n",
    "    b -- the learned bias   matrix (1, num_class)\n",
    "    X -- input data (m, num_feature)\n",
    "    \n",
    "    Return:\n",
    "    prediction -- softmax vector (1, num_feature)\n",
    "    \"\"\"\n",
    "    A = soft_max(linear_forward(X, W, b))\n",
    "    \n",
    "    prediction = np.argmax(A, axis = 1)\n",
    "    \n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 89.333333%\n"
     ]
    }
   ],
   "source": [
    "# Training accuracy\n",
    "Y_train_hat = predict(W, b, X_train)\n",
    "\n",
    "m = X_train.shape[0]\n",
    "num_correct = m - np.count_nonzero((np.squeeze(Y_train) - Y_train_hat))\n",
    "\n",
    "print(\"Training accuracy: %f\" % float(num_correct / m * 100.0) + \"%\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy: 88.990476%\n"
     ]
    }
   ],
   "source": [
    "# Testing accuracy\n",
    "Y_test_hat = predict(W, b, X_test)\n",
    "\n",
    "m = X_test.shape[0]\n",
    "num_correct = m - np.count_nonzero((np.squeeze(Y_test) - Y_test_hat))\n",
    "\n",
    "print(\"Testing accuracy: %f\" % float(num_correct / m * 100.0) + \"%\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK! We got nearly 90% of accuracy for both training and testing data using the simple linear classifier. In the next notebook, we will build a deeper network which includes more non-linear units to improve the accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix: Math for binary logistic regression\n",
    "### For one example $x = \\{x_1, \\dots, x_n \\}$, \n",
    "we have $w = \\{w_1, \\dots, w_n \\}$, and $b$\n",
    "\n",
    "$$z = \\sum\\limits_{i=1}^{n} w_i x_i + b$$\n",
    "\n",
    "$$a = \\sigma(z) = \\frac{1}{1+e^{-z}}$$\n",
    "\n",
    "Then, the cost function is \n",
    "$$ \\mathcal{L}(a, y) =  - y  \\log(a) - (1-y )  \\log(1-a)$$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Now we derive the derivatives for gradient decent:\n",
    "\n",
    "$$da = -\\frac{y}{a} +\\frac{1-y}{1-a}$$\n",
    "$$dz = da*a*(1-a) = a - y$$\n",
    "$$dw_i = dz * x = (a - y)*x_i$$\n",
    "$$db = dz = a - y$$\n",
    "\n",
    "### For vectorization and m training examples:\n",
    "\n",
    "Given \n",
    "$$\n",
    "X_{(m, n)}\n",
    "=\n",
    "\\begin{bmatrix} \n",
    "\\dots x^{(1)} \\dots \\\\\n",
    "\\vdots \\\\\n",
    "\\dots x^{(m)} \\dots \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "we need to have\n",
    "$$\n",
    "W_{(n, 1)}\n",
    "=\n",
    "\\begin{bmatrix} \n",
    "w_1  \\\\ \\vdots \\\\ w_n \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$$\n",
    "b_{(m, 1)}\n",
    "=\n",
    "\\begin{bmatrix} \n",
    "b_1  \\\\ \\vdots \\\\ b_m \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "#### 1. Forward propagation:\n",
    "\n",
    "$$Z = X W + b$$\n",
    "$$A = \\sigma(Z) $$\n",
    "\n",
    "\n",
    "#### 2. The cost is then computed by summing over all training examples:\n",
    "\n",
    "$$ J = \\frac{1}{m} ||\\mathcal{L}(A, Y)||_F = \\frac{1}{m} \\sum_{i=1}^m \\mathcal{L}(a^{(i)}, y^{(i)})$$\n",
    "\n",
    "#### 3. Back propagation:\n",
    "$$dZ = A - Y $$\n",
    "$$ \\frac{\\partial J}{\\partial w} = \\frac{1}{m}X^T(A-Y)$$\n",
    "$$ \\frac{\\partial J}{\\partial b} = \\frac{1}{m} (A-Y).sum() = \\frac{1}{m} \\sum_{i=1}^m (a^{(i)}-y^{(i)})$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
